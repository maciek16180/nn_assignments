{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 25 days\n",
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 25 days\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using gpu device 0: GeForce GTX 780 (CNMeM is enabled)\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "import theano.tensor.signal.downsample\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}))\n",
    "\n",
    "cifar10_train = CIFAR10((\"train\",), subset=slice(None, 40000))\n",
    "#this stream will shuffle the CIFAR10 set and return us batches of 25 examples\n",
    "cifar10_train_stream = DataStream.default_stream(\n",
    "    cifar10_train,\n",
    "    iteration_scheme=ShuffledScheme(cifar10_train.num_examples, 25))\n",
    "                                               \n",
    "cifar10_validation = CIFAR10((\"train\",), subset=slice(40000, None))\n",
    "\n",
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "cifar10_validation_stream = DataStream.default_stream(\n",
    "    cifar10_validation, iteration_scheme=SequentialScheme(cifar10_validation.num_examples, 100))\n",
    "cifar10_test = CIFAR10((\"test\",))\n",
    "cifar10_test_stream = DataStream.default_stream(\n",
    "    cifar10_test, iteration_scheme=SequentialScheme(cifar10_test.num_examples, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (25, 3, 32, 32) containing float32\n",
      " - an array of size (25, 1) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (100, 3, 32, 32) containing float32\n",
      " - an array of size (100, 1) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (cifar10_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar10_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar10_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################################\n",
    "#   BUILDING A COMPUTATIONAL GRAPH WITH THEANO   #\n",
    "##################################################\n",
    "\n",
    "X = theano.tensor.tensor4('X')\n",
    "Y = theano.tensor.matrix('Y', dtype='uint8')\n",
    "\n",
    "model_parameters = []\n",
    "\n",
    "\n",
    "# CONVOLUTIONAL LAYER 1\n",
    "\n",
    "#The shape is: num_out_filters x num_in_filters x filter_height x filter_width\n",
    "num_filters_1 = 40\n",
    "CW1 = theano.shared(np.zeros((num_filters_1,3,3,3), dtype='float32'), name='CW1')\n",
    "CW1.tag.initializer = IsotropicGaussian(0.01)\n",
    "\n",
    "CB1 = theano.shared(np.zeros((num_filters_1,), dtype='float32'), name='CB1')\n",
    "CB1.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW1, CB1]\n",
    "\n",
    "conv1 = theano.tensor.nnet.conv2d(X, CW1) + CB1.dimshuffle('x',0,'x','x')\n",
    "after_C1 = theano.tensor.maximum(0.0, conv1)\n",
    "after_P1 = theano.tensor.signal.downsample.max_pool_2d(after_C1, (3,3), ignore_border=True)\n",
    "\n",
    "\n",
    "# CONVOLUTIONAL LAYER 2\n",
    "\n",
    "num_filters_2 = 50\n",
    "CW2 = theano.shared(np.zeros((num_filters_2,num_filters_1,3,3), dtype='float32'), name='CW2')\n",
    "CW2.tag.initializer = IsotropicGaussian(0.01)\n",
    "\n",
    "CB2 = theano.shared(np.zeros((num_filters_2,), dtype='float32'), name='CB2')\n",
    "CB2.tag.initializer = Constant(0.0)\n",
    "model_parameters += [CW2, CB2]\n",
    "\n",
    "conv2 = theano.tensor.nnet.conv2d(after_P1, CW2) + CB2.dimshuffle('x',0,'x','x')\n",
    "after_C2 = theano.tensor.maximum(0.0, conv2)\n",
    "after_P2 = theano.tensor.signal.downsample.max_pool_2d(after_C2, (2,2), ignore_border=True)\n",
    "\n",
    "\n",
    "# FULLY CONNECTED LAYER 1\n",
    "\n",
    "num_fw3_hidden = 500\n",
    "FW3 = theano.shared(np.zeros((num_filters_2 * 16, num_fw3_hidden), dtype='float32'), name='FW3')\n",
    "FW3.tag.initializer = IsotropicGaussian(0.01)\n",
    "\n",
    "FB3 = theano.shared(np.zeros((num_fw3_hidden,), dtype='float32'), name='FB3')\n",
    "FB3.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW3, FB3]\n",
    "\n",
    "dot3 = theano.tensor.dot(after_P2.flatten(2), FW3) + FB3.dimshuffle('x',0)\n",
    "after_F3 = theano.tensor.maximum(0.0, dot3)\n",
    "\n",
    "\n",
    "# FULLY CONNECTED LAYER 2\n",
    "\n",
    "num_fw4_hidden = 10\n",
    "FW4 = theano.shared(np.zeros((num_fw3_hidden, num_fw4_hidden), dtype='float32'), name='FW4')\n",
    "FW4.tag.initializer = IsotropicGaussian(0.01)\n",
    "\n",
    "FB4 = theano.shared(np.zeros((num_fw4_hidden,), dtype='float32'), name='FB4')\n",
    "FB4.tag.initializer = Constant(0.0)\n",
    "model_parameters += [FW4, FB4]\n",
    "\n",
    "after_F4 = theano.tensor.dot(after_F3, FW4) + FB4.dimshuffle('x',0)\n",
    "\n",
    "\n",
    "# COMPUTING PREDICTIONS\n",
    "\n",
    "log_probs = theano.tensor.nnet.softmax(after_F4)\n",
    "predictions = theano.tensor.argmax(log_probs, axis=1)\n",
    "\n",
    "predict = theano.function([X], predictions)\n",
    "\n",
    "\n",
    "# DROPOUT\n",
    "\n",
    "aff_layers = [after_F3]\n",
    "conv_layers = [after_C1, after_C2]\n",
    "\n",
    "rng = RandomStreams()\n",
    "dropout = True\n",
    "\n",
    "input_drop = 0.\n",
    "conv_drop = 0.\n",
    "aff_drop = 0.5\n",
    "\n",
    "if dropout:\n",
    "    \n",
    "    if input_drop > 0.:\n",
    "        mask = rng.uniform((X.shape[0],)) >= input_drop\n",
    "        mask /= (1.0 - input_drop)\n",
    "        mask = mask.dimshuffle(0,'x','x','x')\n",
    "        new_X = X*mask\n",
    "        log_probs = theano.clone(log_probs, replace=[(X, new_X)])\n",
    "        predictions = theano.clone(predictions, replace=[(X, new_X)])\n",
    "    \n",
    "    if conv_drop > 0.:\n",
    "        for cl in conv_layers:\n",
    "            mask = rng.uniform((cl.shape[1],)) >= conv_drop\n",
    "            mask = mask.dimshuffle('x',0,'x','x')\n",
    "            mask /= (1.0 - conv_drop)\n",
    "            new_cl = cl*mask\n",
    "            log_probs = theano.clone(log_probs, replace=[(cl, new_cl)])\n",
    "            predictions = theano.clone(predictions, replace=[(cl, new_cl)])\n",
    "        \n",
    "    if aff_drop > 0.:\n",
    "        for al in aff_layers:\n",
    "            mask = rng.uniform((al.shape[1],)) >= aff_drop\n",
    "            mask = mask.dimshuffle('x',0)\n",
    "            mask /= (1.0 - aff_drop)\n",
    "            new_al = al*mask\n",
    "            log_probs = theano.clone(log_probs, replace=[(al, new_al)])\n",
    "            predictions = theano.clone(predictions, replace=[(al, new_al)])\n",
    "\n",
    "\n",
    "    \n",
    "# CALCULATING THE COST\n",
    "    \n",
    "error_rate = theano.tensor.neq(predictions, Y.ravel()).mean()\n",
    "nll = -theano.tensor.log(log_probs[theano.tensor.arange(Y.shape[0]), Y.ravel()]).mean()    \n",
    "\n",
    "weight_decay = 0.0\n",
    "for p in model_parameters:\n",
    "    if p.name[1] == 'W':\n",
    "        weight_decay += 1e-3 * (p**2).sum()\n",
    "\n",
    "cost = nll + weight_decay\n",
    "\n",
    "\n",
    "updates = []\n",
    "\n",
    "lrate = theano.tensor.scalar('lrate',dtype='float32')\n",
    "momentum = theano.tensor.scalar('momentum',dtype='float32')\n",
    "\n",
    "gradients = theano.grad(cost, model_parameters)\n",
    "\n",
    "velocities = [theano.shared(np.zeros_like(p.get_value()), name='V_%s' %(p.name, )) for p in model_parameters]\n",
    "\n",
    "for p,g,v in zip(model_parameters, gradients, velocities):\n",
    "    v_new = momentum*v - lrate*g\n",
    "    p_new = p + v_new\n",
    "    updates += [(v,v_new), (p,p_new)]\n",
    "\n",
    "\n",
    "# MAKING A TRAIN FUNCTION\n",
    "\n",
    "train_step = theano.function([X,Y,lrate,momentum],[cost, error_rate, nll, weight_decay],updates=updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_error_rate(stream):\n",
    "    errs = 0.0\n",
    "    num_samples = 0.0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        errs += (predict(X)!=Y.ravel()).sum()\n",
    "        num_samples += Y.shape[0]\n",
    "    return errs/num_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#utilities to save values of parameters and to load them\n",
    "\n",
    "def init_parameters():\n",
    "    rng = np.random.RandomState(1234)\n",
    "    for p in model_parameters:\n",
    "        p.set_value(p.tag.initializer.generate(rng, p.get_value().shape))\n",
    "\n",
    "def snapshot_parameters():\n",
    "    return [p.get_value(borrow=False) for p in model_parameters]\n",
    "\n",
    "def load_parameters(snapshot):\n",
    "    for p, s in zip(model_parameters, snapshot):\n",
    "        p.set_value(s, borrow=False)\n",
    "        \n",
    "def simulate_data(batch_X, n, k):\n",
    "    res = batch_X\n",
    "    for i in range(n):\n",
    "        new_data = np.copy(batch_X)\n",
    "        for i in range(new_data.shape[0]):\n",
    "            new_data[i] = np.roll(new_data[i], np.random.randint(-k,k+1), axis=1)\n",
    "            new_data[i] = np.roll(new_data[i], np.random.randint(-k,k+1), axis=2)\n",
    "        res = np.vstack((res, new_data))\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# init training\n",
    "\n",
    "i = 0\n",
    "e = 0\n",
    "\n",
    "init_parameters()\n",
    "for v in velocities:\n",
    "    v.set_value(np.zeros_like(v.get_value()))\n",
    "\n",
    "best_valid_error_rate = np.inf\n",
    "best_params = snapshot_parameters()\n",
    "best_params_epoch = 0\n",
    "\n",
    "train_erros = []\n",
    "train_loss = []\n",
    "train_nll = []\n",
    "validation_errors = []\n",
    "\n",
    "number_of_epochs = 3\n",
    "patience_expansion = 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At minibatch 100, batch loss 2.333737, batch nll 2.292719, batch error rate 80.000000%\n",
      "At minibatch 200, batch loss 2.355398, batch nll 2.315985, batch error rate 96.000000%\n",
      "At minibatch 300, batch loss 2.357580, batch nll 2.319704, batch error rate 92.000000%\n",
      "At minibatch 400, batch loss 2.341331, batch nll 2.304919, batch error rate 92.000000%\n",
      "At minibatch 500, batch loss 2.336439, batch nll 2.301414, batch error rate 96.000000%\n",
      "At minibatch 600, batch loss 2.329007, batch nll 2.295256, batch error rate 76.000000%\n",
      "At minibatch 700, batch loss 2.324102, batch nll 2.291134, batch error rate 84.000000%\n",
      "At minibatch 800, batch loss 2.228847, batch nll 2.194035, batch error rate 96.000000%\n",
      "At minibatch 900, batch loss 1.835320, batch nll 1.799589, batch error rate 80.000000%\n",
      "At minibatch 1000, batch loss 2.125763, batch nll 2.088988, batch error rate 88.000000%\n",
      "At minibatch 1100, batch loss 2.012003, batch nll 1.973946, batch error rate 72.000000%\n",
      "At minibatch 1200, batch loss 1.963574, batch nll 1.922738, batch error rate 72.000000%\n",
      "At minibatch 1300, batch loss 2.079412, batch nll 2.035440, batch error rate 72.000000%\n",
      "At minibatch 1400, batch loss 1.960432, batch nll 1.913706, batch error rate 60.000000%\n",
      "At minibatch 1500, batch loss 1.788570, batch nll 1.738595, batch error rate 76.000000%\n",
      "At minibatch 1600, batch loss 1.511071, batch nll 1.456935, batch error rate 52.000000%\n",
      "After epoch 1: valid_err_rate: 63.120000% currently going to do 3 epochs\n",
      "After epoch 1: averaged train_err_rate: 80.802500% averaged train nll: 2.115935 averaged train loss: 2.155458\n",
      "At minibatch 1700, batch loss 1.796751, batch nll 1.739539, batch error rate 72.000000%\n",
      "At minibatch 1800, batch loss 1.604879, batch nll 1.543721, batch error rate 72.000000%\n",
      "At minibatch 1900, batch loss 1.796678, batch nll 1.732077, batch error rate 64.000000%\n",
      "At minibatch 2000, batch loss 1.851117, batch nll 1.783601, batch error rate 52.000000%\n",
      "At minibatch 2100, batch loss 1.530987, batch nll 1.460053, batch error rate 68.000000%\n",
      "At minibatch 2200, batch loss 1.640972, batch nll 1.565413, batch error rate 68.000000%\n",
      "At minibatch 2300, batch loss 1.540868, batch nll 1.461657, batch error rate 48.000000%\n",
      "At minibatch 2400, batch loss 1.501195, batch nll 1.419236, batch error rate 56.000000%\n",
      "At minibatch 2500, batch loss 2.378518, batch nll 2.293556, batch error rate 88.000000%\n",
      "At minibatch 2600, batch loss 1.915662, batch nll 1.827182, batch error rate 64.000000%\n",
      "At minibatch 2700, batch loss 1.925548, batch nll 1.834407, batch error rate 60.000000%\n",
      "At minibatch 2800, batch loss 1.694741, batch nll 1.600072, batch error rate 64.000000%\n",
      "At minibatch 2900, batch loss 1.902835, batch nll 1.805205, batch error rate 72.000000%\n",
      "At minibatch 3000, batch loss 1.648980, batch nll 1.548866, batch error rate 48.000000%\n",
      "At minibatch 3100, batch loss 2.156671, batch nll 2.052550, batch error rate 68.000000%\n",
      "At minibatch 3200, batch loss 1.512242, batch nll 1.404303, batch error rate 64.000000%\n",
      "After epoch 2: valid_err_rate: 48.260000% currently going to do 4 epochs\n",
      "After epoch 2: averaged train_err_rate: 57.587500% averaged train nll: 1.570437 averaged train loss: 1.651784\n",
      "At minibatch 3300, batch loss 1.560328, batch nll 1.448806, batch error rate 44.000000%\n",
      "At minibatch 3400, batch loss 1.568421, batch nll 1.453963, batch error rate 48.000000%\n",
      "At minibatch 3500, batch loss 1.608474, batch nll 1.490561, batch error rate 56.000000%\n",
      "At minibatch 3600, batch loss 1.486109, batch nll 1.364293, batch error rate 40.000000%\n",
      "At minibatch 3700, batch loss 1.535960, batch nll 1.410826, batch error rate 64.000000%\n",
      "At minibatch 3800, batch loss 1.698396, batch nll 1.570719, batch error rate 48.000000%\n",
      "At minibatch 3900, batch loss 1.693789, batch nll 1.561503, batch error rate 56.000000%\n",
      "At minibatch 4000, batch loss 1.491346, batch nll 1.356408, batch error rate 60.000000%\n",
      "At minibatch 4100, batch loss 1.306588, batch nll 1.167737, batch error rate 44.000000%\n",
      "At minibatch 4200, batch loss 1.474159, batch nll 1.332331, batch error rate 48.000000%\n",
      "At minibatch 4300, batch loss 1.273079, batch nll 1.128626, batch error rate 36.000000%\n",
      "At minibatch 4400, batch loss 1.400898, batch nll 1.253615, batch error rate 40.000000%\n",
      "At minibatch 4500, batch loss 1.434815, batch nll 1.283747, batch error rate 52.000000%\n",
      "At minibatch 4600, batch loss 1.598015, batch nll 1.443262, batch error rate 52.000000%\n",
      "At minibatch 4700, batch loss 1.558545, batch nll 1.401262, batch error rate 40.000000%\n",
      "At minibatch 4800, batch loss 1.470903, batch nll 1.310027, batch error rate 44.000000%\n",
      "After epoch 3: valid_err_rate: 40.430000% currently going to do 5 epochs\n",
      "After epoch 3: averaged train_err_rate: 50.720000% averaged train nll: 1.400731 averaged train loss: 1.535602\n",
      "At minibatch 4900, batch loss 1.320118, batch nll 1.155546, batch error rate 36.000000%\n",
      "At minibatch 5000, batch loss 1.772129, batch nll 1.603742, batch error rate 60.000000%\n",
      "At minibatch 5100, batch loss 1.140307, batch nll 0.968371, batch error rate 40.000000%\n",
      "At minibatch 5200, batch loss 1.786682, batch nll 1.612885, batch error rate 60.000000%\n",
      "At minibatch 5300, batch loss 1.872014, batch nll 1.694565, batch error rate 64.000000%\n",
      "At minibatch 5400, batch loss 1.600281, batch nll 1.421234, batch error rate 52.000000%\n",
      "At minibatch 5500, batch loss 1.464225, batch nll 1.283865, batch error rate 52.000000%\n",
      "At minibatch 5600, batch loss 1.194886, batch nll 1.012562, batch error rate 32.000000%\n",
      "At minibatch 5700, batch loss 1.512916, batch nll 1.328470, batch error rate 40.000000%\n",
      "At minibatch 5800, batch loss 1.285646, batch nll 1.099464, batch error rate 40.000000%\n",
      "At minibatch 5900, batch loss 1.747238, batch nll 1.559219, batch error rate 48.000000%\n",
      "At minibatch 6000, batch loss 1.544983, batch nll 1.355256, batch error rate 56.000000%\n",
      "At minibatch 6100, batch loss 1.072642, batch nll 0.881593, batch error rate 28.000000%\n",
      "At minibatch 6200, batch loss 1.479125, batch nll 1.286395, batch error rate 48.000000%\n",
      "At minibatch 6300, batch loss 1.491938, batch nll 1.298640, batch error rate 28.000000%\n",
      "At minibatch 6400, batch loss 1.755528, batch nll 1.561109, batch error rate 44.000000%\n",
      "After epoch 4: valid_err_rate: 38.000000% currently going to do 7 epochs\n",
      "After epoch 4: averaged train_err_rate: 45.872500% averaged train nll: 1.277032 averaged train loss: 1.458337\n",
      "At minibatch 6500, batch loss 1.282127, batch nll 1.086196, batch error rate 28.000000%\n",
      "At minibatch 6600, batch loss 1.683558, batch nll 1.486264, batch error rate 44.000000%\n",
      "At minibatch 6700, batch loss 1.123071, batch nll 0.924616, batch error rate 32.000000%\n",
      "At minibatch 6800, batch loss 1.477153, batch nll 1.276741, batch error rate 32.000000%\n",
      "At minibatch 6900, batch loss 1.180896, batch nll 0.979447, batch error rate 44.000000%\n",
      "At minibatch 7000, batch loss 1.549378, batch nll 1.346285, batch error rate 40.000000%\n",
      "At minibatch 7100, batch loss 1.424892, batch nll 1.220502, batch error rate 32.000000%\n",
      "At minibatch 7200, batch loss 1.638849, batch nll 1.433894, batch error rate 48.000000%\n",
      "At minibatch 7300, batch loss 1.041205, batch nll 0.834950, batch error rate 32.000000%\n",
      "At minibatch 7400, batch loss 1.064382, batch nll 0.857420, batch error rate 28.000000%\n",
      "At minibatch 7500, batch loss 1.577205, batch nll 1.370382, batch error rate 52.000000%\n",
      "At minibatch 7600, batch loss 1.516017, batch nll 1.308498, batch error rate 52.000000%\n",
      "At minibatch 7700, batch loss 1.479466, batch nll 1.271489, batch error rate 48.000000%\n",
      "At minibatch 7800, batch loss 1.294787, batch nll 1.086568, batch error rate 28.000000%\n",
      "At minibatch 7900, batch loss 1.699681, batch nll 1.490526, batch error rate 52.000000%\n",
      "At minibatch 8000, batch loss 1.419500, batch nll 1.209759, batch error rate 40.000000%\n",
      "After epoch 5: valid_err_rate: 37.370000% currently going to do 8 epochs\n",
      "After epoch 5: averaged train_err_rate: 41.075000% averaged train nll: 1.158408 averaged train loss: 1.362200\n",
      "At minibatch 8100, batch loss 1.305691, batch nll 1.095133, batch error rate 40.000000%\n",
      "At minibatch 8200, batch loss 0.969115, batch nll 0.757398, batch error rate 20.000000%\n",
      "At minibatch 8300, batch loss 1.053735, batch nll 0.841289, batch error rate 32.000000%\n",
      "At minibatch 8400, batch loss 1.296543, batch nll 1.084100, batch error rate 40.000000%\n",
      "At minibatch 8500, batch loss 1.189592, batch nll 0.977022, batch error rate 36.000000%\n",
      "At minibatch 8600, batch loss 0.852758, batch nll 0.640294, batch error rate 20.000000%\n",
      "At minibatch 8700, batch loss 1.317363, batch nll 1.104536, batch error rate 52.000000%\n",
      "At minibatch 8800, batch loss 1.662183, batch nll 1.448468, batch error rate 48.000000%\n",
      "At minibatch 8900, batch loss 1.149241, batch nll 0.935141, batch error rate 32.000000%\n",
      "At minibatch 9000, batch loss 1.282893, batch nll 1.068111, batch error rate 40.000000%\n",
      "At minibatch 9100, batch loss 1.631696, batch nll 1.416249, batch error rate 56.000000%\n",
      "At minibatch 9200, batch loss 1.130819, batch nll 0.915058, batch error rate 24.000000%\n",
      "At minibatch 9300, batch loss 1.113913, batch nll 0.897548, batch error rate 28.000000%\n",
      "At minibatch 9400, batch loss 1.514335, batch nll 1.298125, batch error rate 40.000000%\n",
      "At minibatch 9500, batch loss 1.302445, batch nll 1.085525, batch error rate 40.000000%\n",
      "At minibatch 9600, batch loss 1.662304, batch nll 1.445441, batch error rate 52.000000%\n",
      "After epoch 6: valid_err_rate: 35.260000% currently going to do 10 epochs\n",
      "After epoch 6: averaged train_err_rate: 38.537500% averaged train nll: 1.088612 averaged train loss: 1.302459\n",
      "At minibatch 9700, batch loss 1.154443, batch nll 0.936478, batch error rate 32.000000%\n",
      "At minibatch 9800, batch loss 1.012176, batch nll 0.793424, batch error rate 24.000000%\n",
      "At minibatch 9900, batch loss 1.202814, batch nll 0.984104, batch error rate 36.000000%\n",
      "At minibatch 10000, batch loss 1.161385, batch nll 0.942129, batch error rate 36.000000%\n",
      "At minibatch 10100, batch loss 1.542248, batch nll 1.322463, batch error rate 44.000000%\n",
      "At minibatch 10200, batch loss 1.322804, batch nll 1.103294, batch error rate 48.000000%\n",
      "At minibatch 10300, batch loss 1.506819, batch nll 1.287518, batch error rate 36.000000%\n",
      "At minibatch 10400, batch loss 1.103978, batch nll 0.884051, batch error rate 20.000000%\n",
      "At minibatch 10500, batch loss 1.738884, batch nll 1.518615, batch error rate 52.000000%\n",
      "At minibatch 10600, batch loss 1.585528, batch nll 1.365058, batch error rate 44.000000%\n",
      "At minibatch 10700, batch loss 0.882118, batch nll 0.661681, batch error rate 20.000000%\n",
      "At minibatch 10800, batch loss 1.079448, batch nll 0.858654, batch error rate 24.000000%\n",
      "At minibatch 10900, batch loss 1.204894, batch nll 0.984034, batch error rate 36.000000%\n",
      "At minibatch 11000, batch loss 1.500851, batch nll 1.279338, batch error rate 48.000000%\n",
      "At minibatch 11100, batch loss 1.056830, batch nll 0.835477, batch error rate 36.000000%\n",
      "At minibatch 11200, batch loss 0.997053, batch nll 0.775326, batch error rate 32.000000%\n",
      "After epoch 7: valid_err_rate: 33.500000% currently going to do 11 epochs\n",
      "After epoch 7: averaged train_err_rate: 36.485000% averaged train nll: 1.037204 averaged train loss: 1.257118\n",
      "At minibatch 11300, batch loss 1.136547, batch nll 0.914659, batch error rate 32.000000%\n",
      "At minibatch 11400, batch loss 1.082106, batch nll 0.859952, batch error rate 32.000000%\n",
      "At minibatch 11500, batch loss 1.381740, batch nll 1.158780, batch error rate 40.000000%\n",
      "At minibatch 11600, batch loss 1.078472, batch nll 0.854856, batch error rate 40.000000%\n",
      "At minibatch 11700, batch loss 1.161156, batch nll 0.937487, batch error rate 28.000000%\n",
      "At minibatch 11800, batch loss 0.996964, batch nll 0.773423, batch error rate 28.000000%\n",
      "At minibatch 11900, batch loss 1.184736, batch nll 0.961161, batch error rate 28.000000%\n",
      "At minibatch 12000, batch loss 1.373621, batch nll 1.150233, batch error rate 48.000000%\n",
      "At minibatch 12100, batch loss 1.006781, batch nll 0.782443, batch error rate 32.000000%\n",
      "At minibatch 12200, batch loss 1.588530, batch nll 1.364055, batch error rate 44.000000%\n",
      "At minibatch 12300, batch loss 1.541831, batch nll 1.317485, batch error rate 48.000000%\n",
      "At minibatch 12400, batch loss 1.528192, batch nll 1.303880, batch error rate 36.000000%\n",
      "At minibatch 12500, batch loss 0.924074, batch nll 0.699675, batch error rate 20.000000%\n",
      "At minibatch 12600, batch loss 1.382152, batch nll 1.157650, batch error rate 56.000000%\n",
      "At minibatch 12700, batch loss 1.059011, batch nll 0.834177, batch error rate 24.000000%\n",
      "At minibatch 12800, batch loss 1.058613, batch nll 0.833490, batch error rate 28.000000%\n",
      "After epoch 8: valid_err_rate: 29.320000% currently going to do 13 epochs\n",
      "After epoch 8: averaged train_err_rate: 34.485000% averaged train nll: 0.982907 averaged train loss: 1.206619\n",
      "At minibatch 12900, batch loss 1.121039, batch nll 0.895755, batch error rate 32.000000%\n",
      "At minibatch 13000, batch loss 1.136575, batch nll 0.910929, batch error rate 40.000000%\n",
      "At minibatch 13100, batch loss 0.915335, batch nll 0.689386, batch error rate 32.000000%\n",
      "At minibatch 13200, batch loss 0.793117, batch nll 0.566887, batch error rate 16.000000%\n",
      "At minibatch 13300, batch loss 1.047964, batch nll 0.821918, batch error rate 32.000000%\n",
      "At minibatch 13400, batch loss 1.246391, batch nll 1.020059, batch error rate 48.000000%\n",
      "At minibatch 13500, batch loss 0.820955, batch nll 0.594651, batch error rate 16.000000%\n",
      "At minibatch 13600, batch loss 1.427753, batch nll 1.201349, batch error rate 44.000000%\n",
      "At minibatch 13700, batch loss 1.236207, batch nll 1.009680, batch error rate 32.000000%\n",
      "At minibatch 13800, batch loss 1.142461, batch nll 0.916040, batch error rate 32.000000%\n",
      "At minibatch 13900, batch loss 1.622678, batch nll 1.396445, batch error rate 44.000000%\n",
      "At minibatch 14000, batch loss 1.098163, batch nll 0.871937, batch error rate 36.000000%\n",
      "At minibatch 14100, batch loss 0.827151, batch nll 0.601268, batch error rate 16.000000%\n",
      "At minibatch 14200, batch loss 1.254699, batch nll 1.028368, batch error rate 48.000000%\n",
      "At minibatch 14300, batch loss 1.368432, batch nll 1.142280, batch error rate 36.000000%\n",
      "At minibatch 14400, batch loss 1.669962, batch nll 1.443472, batch error rate 48.000000%\n",
      "After epoch 9: valid_err_rate: 28.380000% currently going to do 14 epochs\n",
      "After epoch 9: averaged train_err_rate: 33.895000% averaged train nll: 0.960914 averaged train loss: 1.187025\n",
      "At minibatch 14500, batch loss 1.424562, batch nll 1.198250, batch error rate 40.000000%\n",
      "At minibatch 14600, batch loss 1.337372, batch nll 1.110823, batch error rate 48.000000%\n",
      "At minibatch 14700, batch loss 1.338708, batch nll 1.112154, batch error rate 32.000000%\n",
      "At minibatch 14800, batch loss 0.870006, batch nll 0.642607, batch error rate 24.000000%\n",
      "At minibatch 14900, batch loss 1.215157, batch nll 0.987688, batch error rate 20.000000%\n",
      "At minibatch 15000, batch loss 1.239047, batch nll 1.011664, batch error rate 32.000000%\n",
      "At minibatch 15100, batch loss 1.053785, batch nll 0.826023, batch error rate 36.000000%\n",
      "At minibatch 15200, batch loss 1.443865, batch nll 1.215949, batch error rate 36.000000%\n",
      "At minibatch 15300, batch loss 1.447927, batch nll 1.219889, batch error rate 52.000000%\n",
      "At minibatch 15400, batch loss 1.298578, batch nll 1.070288, batch error rate 36.000000%\n",
      "At minibatch 15500, batch loss 1.612537, batch nll 1.384013, batch error rate 32.000000%\n",
      "At minibatch 15600, batch loss 1.299193, batch nll 1.070540, batch error rate 36.000000%\n",
      "At minibatch 15700, batch loss 0.948530, batch nll 0.720200, batch error rate 28.000000%\n",
      "At minibatch 15800, batch loss 1.364419, batch nll 1.135913, batch error rate 28.000000%\n",
      "At minibatch 15900, batch loss 1.157189, batch nll 0.928897, batch error rate 28.000000%\n",
      "At minibatch 16000, batch loss 1.133785, batch nll 0.905602, batch error rate 36.000000%\n",
      "After epoch 10: valid_err_rate: 28.570000% currently going to do 14 epochs\n",
      "After epoch 10: averaged train_err_rate: 32.587500% averaged train nll: 0.930520 averaged train loss: 1.158261\n",
      "At minibatch 16100, batch loss 1.125967, batch nll 0.897434, batch error rate 24.000000%\n",
      "At minibatch 16200, batch loss 1.198341, batch nll 0.969804, batch error rate 40.000000%\n",
      "At minibatch 16300, batch loss 1.144324, batch nll 0.915486, batch error rate 40.000000%\n",
      "At minibatch 16400, batch loss 1.133805, batch nll 0.905060, batch error rate 28.000000%\n",
      "At minibatch 16500, batch loss 1.311318, batch nll 1.082708, batch error rate 40.000000%\n",
      "At minibatch 16600, batch loss 1.172431, batch nll 0.943787, batch error rate 40.000000%\n",
      "At minibatch 16700, batch loss 1.118322, batch nll 0.889439, batch error rate 28.000000%\n",
      "At minibatch 16800, batch loss 1.495356, batch nll 1.266327, batch error rate 48.000000%\n",
      "At minibatch 16900, batch loss 1.048868, batch nll 0.820008, batch error rate 40.000000%\n",
      "At minibatch 17000, batch loss 1.216481, batch nll 0.987553, batch error rate 40.000000%\n",
      "At minibatch 17100, batch loss 1.407797, batch nll 1.179160, batch error rate 36.000000%\n",
      "At minibatch 17200, batch loss 1.227820, batch nll 0.999202, batch error rate 36.000000%\n",
      "At minibatch 17300, batch loss 1.127484, batch nll 0.898822, batch error rate 36.000000%\n",
      "At minibatch 17400, batch loss 0.988457, batch nll 0.759620, batch error rate 24.000000%\n",
      "At minibatch 17500, batch loss 1.272664, batch nll 1.043125, batch error rate 40.000000%\n",
      "At minibatch 17600, batch loss 0.991123, batch nll 0.761553, batch error rate 28.000000%\n",
      "After epoch 11: valid_err_rate: 26.550000% currently going to do 17 epochs\n",
      "After epoch 11: averaged train_err_rate: 31.750000% averaged train nll: 0.904148 averaged train loss: 1.132985\n",
      "At minibatch 17700, batch loss 1.226177, batch nll 0.996556, batch error rate 32.000000%\n",
      "At minibatch 17800, batch loss 1.172945, batch nll 0.943376, batch error rate 28.000000%\n",
      "At minibatch 17900, batch loss 0.920815, batch nll 0.691210, batch error rate 20.000000%\n",
      "At minibatch 18000, batch loss 0.880820, batch nll 0.651272, batch error rate 24.000000%\n",
      "At minibatch 18100, batch loss 1.207574, batch nll 0.978014, batch error rate 28.000000%\n",
      "At minibatch 18200, batch loss 1.354863, batch nll 1.125237, batch error rate 44.000000%\n",
      "At minibatch 18300, batch loss 1.478858, batch nll 1.249108, batch error rate 36.000000%\n",
      "At minibatch 18400, batch loss 1.198988, batch nll 0.969296, batch error rate 36.000000%\n",
      "At minibatch 18500, batch loss 0.917314, batch nll 0.687169, batch error rate 24.000000%\n",
      "At minibatch 18600, batch loss 1.056633, batch nll 0.826573, batch error rate 32.000000%\n",
      "At minibatch 18700, batch loss 0.775640, batch nll 0.546133, batch error rate 8.000000%\n",
      "At minibatch 18800, batch loss 1.119840, batch nll 0.890110, batch error rate 28.000000%\n",
      "At minibatch 18900, batch loss 0.926002, batch nll 0.696333, batch error rate 20.000000%\n",
      "At minibatch 19000, batch loss 0.881609, batch nll 0.651895, batch error rate 16.000000%\n",
      "At minibatch 19100, batch loss 0.711634, batch nll 0.481713, batch error rate 16.000000%\n",
      "At minibatch 19200, batch loss 0.860186, batch nll 0.630143, batch error rate 20.000000%\n",
      "After epoch 12: valid_err_rate: 27.330000% currently going to do 17 epochs\n",
      "After epoch 12: averaged train_err_rate: 30.920000% averaged train nll: 0.886284 averaged train loss: 1.116015\n",
      "At minibatch 19300, batch loss 0.893428, batch nll 0.663232, batch error rate 24.000000%\n",
      "At minibatch 19400, batch loss 1.523319, batch nll 1.293082, batch error rate 52.000000%\n",
      "At minibatch 19500, batch loss 1.378115, batch nll 1.147453, batch error rate 36.000000%\n",
      "At minibatch 19600, batch loss 1.062849, batch nll 0.832126, batch error rate 40.000000%\n",
      "At minibatch 19700, batch loss 1.376896, batch nll 1.146165, batch error rate 28.000000%\n",
      "At minibatch 19800, batch loss 1.411879, batch nll 1.181018, batch error rate 40.000000%\n",
      "At minibatch 19900, batch loss 1.291753, batch nll 1.060981, batch error rate 40.000000%\n",
      "At minibatch 20000, batch loss 1.029102, batch nll 0.798267, batch error rate 32.000000%\n",
      "At minibatch 20100, batch loss 0.885000, batch nll 0.654073, batch error rate 20.000000%\n",
      "At minibatch 20200, batch loss 1.122978, batch nll 0.891874, batch error rate 32.000000%\n",
      "At minibatch 20300, batch loss 1.323903, batch nll 1.093082, batch error rate 48.000000%\n",
      "At minibatch 20400, batch loss 0.879919, batch nll 0.649095, batch error rate 16.000000%\n",
      "At minibatch 20500, batch loss 1.414892, batch nll 1.183764, batch error rate 48.000000%\n",
      "At minibatch 20600, batch loss 0.972718, batch nll 0.741738, batch error rate 24.000000%\n",
      "At minibatch 20700, batch loss 1.049090, batch nll 0.818211, batch error rate 32.000000%\n",
      "At minibatch 20800, batch loss 1.275449, batch nll 1.044491, batch error rate 52.000000%\n",
      "After epoch 13: valid_err_rate: 26.110000% currently going to do 20 epochs\n",
      "After epoch 13: averaged train_err_rate: 30.505000% averaged train nll: 0.864377 averaged train loss: 1.095138\n",
      "At minibatch 20900, batch loss 1.182056, batch nll 0.950958, batch error rate 32.000000%\n",
      "At minibatch 21000, batch loss 0.874043, batch nll 0.643053, batch error rate 28.000000%\n",
      "At minibatch 21100, batch loss 1.062251, batch nll 0.831094, batch error rate 28.000000%\n",
      "At minibatch 21200, batch loss 0.874368, batch nll 0.642827, batch error rate 20.000000%\n",
      "At minibatch 21300, batch loss 0.819175, batch nll 0.587875, batch error rate 24.000000%\n",
      "At minibatch 21400, batch loss 0.913981, batch nll 0.682739, batch error rate 28.000000%\n",
      "At minibatch 21500, batch loss 1.141006, batch nll 0.909445, batch error rate 28.000000%\n",
      "At minibatch 21600, batch loss 1.108208, batch nll 0.876735, batch error rate 20.000000%\n",
      "At minibatch 21700, batch loss 1.049108, batch nll 0.818004, batch error rate 28.000000%\n",
      "At minibatch 21800, batch loss 0.924893, batch nll 0.693451, batch error rate 16.000000%\n",
      "At minibatch 21900, batch loss 1.212543, batch nll 0.981288, batch error rate 36.000000%\n",
      "At minibatch 22000, batch loss 1.090083, batch nll 0.858974, batch error rate 28.000000%\n",
      "At minibatch 22100, batch loss 1.226077, batch nll 0.994682, batch error rate 32.000000%\n",
      "At minibatch 22200, batch loss 1.004147, batch nll 0.772602, batch error rate 24.000000%\n",
      "At minibatch 22300, batch loss 0.765047, batch nll 0.533445, batch error rate 16.000000%\n",
      "At minibatch 22400, batch loss 0.913112, batch nll 0.681508, batch error rate 24.000000%\n",
      "After epoch 14: valid_err_rate: 25.870000% currently going to do 22 epochs\n",
      "After epoch 14: averaged train_err_rate: 30.010000% averaged train nll: 0.854828 averaged train loss: 1.086176\n",
      "At minibatch 22500, batch loss 1.013640, batch nll 0.781913, batch error rate 32.000000%\n",
      "At minibatch 22600, batch loss 0.978463, batch nll 0.746694, batch error rate 24.000000%\n",
      "At minibatch 22700, batch loss 0.902184, batch nll 0.670667, batch error rate 16.000000%\n",
      "At minibatch 22800, batch loss 1.013000, batch nll 0.781424, batch error rate 36.000000%\n",
      "At minibatch 22900, batch loss 1.719830, batch nll 1.488197, batch error rate 72.000000%\n",
      "At minibatch 23000, batch loss 0.974937, batch nll 0.743096, batch error rate 24.000000%\n",
      "At minibatch 23100, batch loss 1.145151, batch nll 0.913421, batch error rate 24.000000%\n",
      "At minibatch 23200, batch loss 0.710622, batch nll 0.478786, batch error rate 24.000000%\n",
      "At minibatch 23300, batch loss 0.957979, batch nll 0.726270, batch error rate 28.000000%\n",
      "At minibatch 23400, batch loss 1.065843, batch nll 0.834075, batch error rate 28.000000%\n",
      "At minibatch 23500, batch loss 1.082965, batch nll 0.851225, batch error rate 32.000000%\n",
      "At minibatch 23600, batch loss 0.893489, batch nll 0.661772, batch error rate 24.000000%\n",
      "At minibatch 23700, batch loss 1.324033, batch nll 1.092041, batch error rate 36.000000%\n",
      "At minibatch 23800, batch loss 0.886343, batch nll 0.654782, batch error rate 12.000000%\n",
      "At minibatch 23900, batch loss 1.062808, batch nll 0.831219, batch error rate 28.000000%\n",
      "At minibatch 24000, batch loss 1.016396, batch nll 0.784620, batch error rate 28.000000%\n",
      "After epoch 15: valid_err_rate: 25.940000% currently going to do 22 epochs\n",
      "After epoch 15: averaged train_err_rate: 29.337500% averaged train nll: 0.845478 averaged train loss: 1.077172\n",
      "At minibatch 24100, batch loss 1.044983, batch nll 0.813127, batch error rate 28.000000%\n",
      "At minibatch 24200, batch loss 0.734405, batch nll 0.502330, batch error rate 16.000000%\n",
      "At minibatch 24300, batch loss 1.018718, batch nll 0.786737, batch error rate 24.000000%\n",
      "At minibatch 24400, batch loss 1.027439, batch nll 0.795662, batch error rate 28.000000%\n",
      "At minibatch 24500, batch loss 1.068665, batch nll 0.836728, batch error rate 24.000000%\n",
      "At minibatch 24600, batch loss 1.078291, batch nll 0.846280, batch error rate 24.000000%\n",
      "At minibatch 24700, batch loss 1.600265, batch nll 1.368247, batch error rate 44.000000%\n",
      "At minibatch 24800, batch loss 1.097859, batch nll 0.865593, batch error rate 24.000000%\n",
      "At minibatch 24900, batch loss 0.898479, batch nll 0.666207, batch error rate 20.000000%\n",
      "At minibatch 25000, batch loss 1.024890, batch nll 0.792628, batch error rate 32.000000%\n",
      "At minibatch 25100, batch loss 1.052739, batch nll 0.820358, batch error rate 16.000000%\n",
      "At minibatch 25200, batch loss 0.928697, batch nll 0.696315, batch error rate 28.000000%\n",
      "At minibatch 25300, batch loss 0.838024, batch nll 0.605783, batch error rate 16.000000%\n",
      "At minibatch 25400, batch loss 0.848298, batch nll 0.616111, batch error rate 24.000000%\n",
      "At minibatch 25500, batch loss 1.134781, batch nll 0.902440, batch error rate 20.000000%\n",
      "At minibatch 25600, batch loss 0.911269, batch nll 0.679008, batch error rate 20.000000%\n",
      "After epoch 16: valid_err_rate: 24.350000% currently going to do 25 epochs\n",
      "After epoch 16: averaged train_err_rate: 29.190000% averaged train nll: 0.831832 averaged train loss: 1.063963\n",
      "At minibatch 25700, batch loss 0.848546, batch nll 0.616088, batch error rate 24.000000%\n",
      "At minibatch 25800, batch loss 0.872803, batch nll 0.640218, batch error rate 24.000000%\n",
      "At minibatch 25900, batch loss 0.870091, batch nll 0.637650, batch error rate 20.000000%\n",
      "At minibatch 26000, batch loss 0.911764, batch nll 0.679127, batch error rate 20.000000%\n",
      "At minibatch 26100, batch loss 1.141638, batch nll 0.908933, batch error rate 36.000000%\n",
      "At minibatch 26200, batch loss 1.191577, batch nll 0.958919, batch error rate 40.000000%\n",
      "At minibatch 26300, batch loss 0.891211, batch nll 0.658525, batch error rate 12.000000%\n",
      "At minibatch 26400, batch loss 1.318303, batch nll 1.085655, batch error rate 32.000000%\n",
      "At minibatch 26500, batch loss 1.163180, batch nll 0.930296, batch error rate 40.000000%\n",
      "At minibatch 26600, batch loss 1.120347, batch nll 0.887510, batch error rate 32.000000%\n",
      "At minibatch 26700, batch loss 1.461506, batch nll 1.228807, batch error rate 44.000000%\n",
      "At minibatch 26800, batch loss 0.844668, batch nll 0.612063, batch error rate 16.000000%\n",
      "At minibatch 26900, batch loss 0.870529, batch nll 0.638088, batch error rate 8.000000%\n",
      "At minibatch 27000, batch loss 1.509970, batch nll 1.277348, batch error rate 36.000000%\n",
      "At minibatch 27100, batch loss 0.828709, batch nll 0.596143, batch error rate 16.000000%\n",
      "At minibatch 27200, batch loss 1.380292, batch nll 1.147494, batch error rate 32.000000%\n",
      "After epoch 17: valid_err_rate: 25.880000% currently going to do 25 epochs\n",
      "After epoch 17: averaged train_err_rate: 28.662500% averaged train nll: 0.820375 averaged train loss: 1.053008\n",
      "At minibatch 27300, batch loss 1.056139, batch nll 0.823505, batch error rate 24.000000%\n",
      "At minibatch 27400, batch loss 0.658821, batch nll 0.425831, batch error rate 24.000000%\n",
      "At minibatch 27500, batch loss 1.093659, batch nll 0.860713, batch error rate 32.000000%\n",
      "At minibatch 27600, batch loss 1.276956, batch nll 1.044091, batch error rate 40.000000%\n",
      "At minibatch 27700, batch loss 1.746622, batch nll 1.513474, batch error rate 40.000000%\n",
      "At minibatch 27800, batch loss 0.593380, batch nll 0.360486, batch error rate 12.000000%\n",
      "At minibatch 27900, batch loss 0.951530, batch nll 0.718526, batch error rate 16.000000%\n",
      "At minibatch 28000, batch loss 0.911635, batch nll 0.678804, batch error rate 28.000000%\n",
      "At minibatch 28100, batch loss 0.774309, batch nll 0.541307, batch error rate 20.000000%\n",
      "At minibatch 28200, batch loss 1.165661, batch nll 0.932612, batch error rate 24.000000%\n",
      "At minibatch 28300, batch loss 1.131351, batch nll 0.898223, batch error rate 32.000000%\n",
      "At minibatch 28400, batch loss 0.999829, batch nll 0.766632, batch error rate 28.000000%\n",
      "At minibatch 28500, batch loss 1.294847, batch nll 1.061735, batch error rate 36.000000%\n",
      "At minibatch 28600, batch loss 0.824616, batch nll 0.591911, batch error rate 20.000000%\n",
      "At minibatch 28700, batch loss 0.980406, batch nll 0.747496, batch error rate 32.000000%\n",
      "At minibatch 28800, batch loss 1.054087, batch nll 0.821069, batch error rate 32.000000%\n",
      "After epoch 18: valid_err_rate: 24.660000% currently going to do 25 epochs\n",
      "After epoch 18: averaged train_err_rate: 28.405000% averaged train nll: 0.814661 averaged train loss: 1.047622\n",
      "At minibatch 28900, batch loss 0.926816, batch nll 0.693784, batch error rate 36.000000%\n",
      "At minibatch 29000, batch loss 0.903216, batch nll 0.670125, batch error rate 28.000000%\n",
      "At minibatch 29100, batch loss 0.879032, batch nll 0.645868, batch error rate 20.000000%\n",
      "At minibatch 29200, batch loss 1.098136, batch nll 0.865016, batch error rate 28.000000%\n",
      "At minibatch 29300, batch loss 1.084996, batch nll 0.851782, batch error rate 40.000000%\n",
      "At minibatch 29400, batch loss 1.192573, batch nll 0.959410, batch error rate 36.000000%\n",
      "At minibatch 29500, batch loss 1.153792, batch nll 0.920473, batch error rate 36.000000%\n",
      "At minibatch 29600, batch loss 1.552905, batch nll 1.319328, batch error rate 48.000000%\n",
      "At minibatch 29700, batch loss 1.236052, batch nll 1.002584, batch error rate 32.000000%\n",
      "At minibatch 29800, batch loss 1.139881, batch nll 0.906217, batch error rate 36.000000%\n",
      "At minibatch 29900, batch loss 0.914833, batch nll 0.681085, batch error rate 28.000000%\n",
      "At minibatch 30000, batch loss 0.816152, batch nll 0.582666, batch error rate 16.000000%\n",
      "At minibatch 30100, batch loss 0.980568, batch nll 0.747082, batch error rate 16.000000%\n",
      "At minibatch 30200, batch loss 1.075140, batch nll 0.841788, batch error rate 20.000000%\n",
      "At minibatch 30300, batch loss 0.913977, batch nll 0.680787, batch error rate 20.000000%\n",
      "At minibatch 30400, batch loss 1.000557, batch nll 0.767351, batch error rate 32.000000%\n",
      "After epoch 19: valid_err_rate: 25.830000% currently going to do 25 epochs\n",
      "After epoch 19: averaged train_err_rate: 28.105000% averaged train nll: 0.805985 averaged train loss: 1.039311\n",
      "At minibatch 30500, batch loss 0.931310, batch nll 0.698148, batch error rate 20.000000%\n",
      "At minibatch 30600, batch loss 1.254528, batch nll 1.021272, batch error rate 48.000000%\n",
      "At minibatch 30700, batch loss 1.359553, batch nll 1.126271, batch error rate 48.000000%\n",
      "At minibatch 30800, batch loss 1.016892, batch nll 0.783516, batch error rate 32.000000%\n",
      "At minibatch 30900, batch loss 1.049749, batch nll 0.816378, batch error rate 32.000000%\n",
      "At minibatch 31000, batch loss 1.219836, batch nll 0.986444, batch error rate 28.000000%\n",
      "At minibatch 31100, batch loss 0.911776, batch nll 0.678278, batch error rate 28.000000%\n",
      "At minibatch 31200, batch loss 1.286057, batch nll 1.052865, batch error rate 32.000000%\n",
      "At minibatch 31300, batch loss 1.167883, batch nll 0.934717, batch error rate 36.000000%\n",
      "At minibatch 31400, batch loss 1.586970, batch nll 1.353887, batch error rate 48.000000%\n",
      "At minibatch 31500, batch loss 1.243211, batch nll 1.010005, batch error rate 32.000000%\n",
      "At minibatch 31600, batch loss 1.198725, batch nll 0.965444, batch error rate 40.000000%\n",
      "At minibatch 31700, batch loss 1.145094, batch nll 0.911872, batch error rate 28.000000%\n",
      "At minibatch 31800, batch loss 1.180923, batch nll 0.947655, batch error rate 36.000000%\n",
      "At minibatch 31900, batch loss 0.790625, batch nll 0.557242, batch error rate 28.000000%\n",
      "At minibatch 32000, batch loss 1.075501, batch nll 0.842186, batch error rate 28.000000%\n",
      "After epoch 20: valid_err_rate: 24.430000% currently going to do 25 epochs\n",
      "After epoch 20: averaged train_err_rate: 27.860000% averaged train nll: 0.801604 averaged train loss: 1.034866\n",
      "At minibatch 32100, batch loss 1.180250, batch nll 0.946802, batch error rate 40.000000%\n",
      "At minibatch 32200, batch loss 0.912202, batch nll 0.678577, batch error rate 32.000000%\n",
      "At minibatch 32300, batch loss 1.007235, batch nll 0.773647, batch error rate 40.000000%\n",
      "At minibatch 32400, batch loss 0.898303, batch nll 0.664723, batch error rate 20.000000%\n",
      "At minibatch 32500, batch loss 0.816593, batch nll 0.582839, batch error rate 20.000000%\n",
      "At minibatch 32600, batch loss 0.890505, batch nll 0.656557, batch error rate 16.000000%\n",
      "At minibatch 32700, batch loss 1.005663, batch nll 0.771969, batch error rate 36.000000%\n",
      "At minibatch 32800, batch loss 1.291252, batch nll 1.057159, batch error rate 36.000000%\n",
      "At minibatch 32900, batch loss 1.138464, batch nll 0.904374, batch error rate 40.000000%\n",
      "At minibatch 33000, batch loss 1.045988, batch nll 0.811882, batch error rate 28.000000%\n",
      "At minibatch 33100, batch loss 0.959465, batch nll 0.725193, batch error rate 32.000000%\n",
      "At minibatch 33200, batch loss 1.039951, batch nll 0.805688, batch error rate 32.000000%\n",
      "At minibatch 33300, batch loss 0.904638, batch nll 0.670373, batch error rate 28.000000%\n",
      "At minibatch 33400, batch loss 1.312828, batch nll 1.078707, batch error rate 44.000000%\n",
      "At minibatch 33500, batch loss 1.085333, batch nll 0.851152, batch error rate 24.000000%\n",
      "At minibatch 33600, batch loss 1.193437, batch nll 0.959181, batch error rate 40.000000%\n",
      "After epoch 21: valid_err_rate: 23.920000% currently going to do 32 epochs\n",
      "After epoch 21: averaged train_err_rate: 27.442500% averaged train nll: 0.786997 averaged train loss: 1.020925\n",
      "At minibatch 33700, batch loss 0.726811, batch nll 0.492392, batch error rate 12.000000%\n",
      "At minibatch 33800, batch loss 0.966161, batch nll 0.731737, batch error rate 32.000000%\n",
      "At minibatch 33900, batch loss 0.876723, batch nll 0.642290, batch error rate 28.000000%\n",
      "At minibatch 34000, batch loss 0.971175, batch nll 0.736617, batch error rate 24.000000%\n",
      "At minibatch 34100, batch loss 0.985150, batch nll 0.750553, batch error rate 28.000000%\n",
      "At minibatch 34200, batch loss 1.283093, batch nll 1.048537, batch error rate 48.000000%\n",
      "At minibatch 34300, batch loss 1.049272, batch nll 0.814683, batch error rate 32.000000%\n",
      "At minibatch 34400, batch loss 0.989335, batch nll 0.754691, batch error rate 28.000000%\n",
      "At minibatch 34500, batch loss 1.098532, batch nll 0.863987, batch error rate 20.000000%\n",
      "At minibatch 34600, batch loss 0.956165, batch nll 0.721357, batch error rate 16.000000%\n",
      "At minibatch 34700, batch loss 1.298005, batch nll 1.063439, batch error rate 32.000000%\n",
      "At minibatch 34800, batch loss 1.041953, batch nll 0.807177, batch error rate 32.000000%\n",
      "At minibatch 34900, batch loss 0.894417, batch nll 0.659607, batch error rate 16.000000%\n",
      "At minibatch 35000, batch loss 0.926523, batch nll 0.691768, batch error rate 20.000000%\n",
      "At minibatch 35100, batch loss 1.092219, batch nll 0.857314, batch error rate 36.000000%\n",
      "At minibatch 35200, batch loss 1.058722, batch nll 0.823723, batch error rate 20.000000%\n",
      "After epoch 22: valid_err_rate: 24.020000% currently going to do 32 epochs\n",
      "After epoch 22: averaged train_err_rate: 27.177500% averaged train nll: 0.780203 averaged train loss: 1.014829\n",
      "At minibatch 35300, batch loss 1.243671, batch nll 1.008587, batch error rate 32.000000%\n",
      "At minibatch 35400, batch loss 0.825247, batch nll 0.589961, batch error rate 20.000000%\n",
      "At minibatch 35500, batch loss 0.927073, batch nll 0.691789, batch error rate 24.000000%\n",
      "At minibatch 35600, batch loss 1.113360, batch nll 0.878106, batch error rate 28.000000%\n",
      "At minibatch 35700, batch loss 0.930053, batch nll 0.694722, batch error rate 24.000000%\n",
      "At minibatch 35800, batch loss 1.015644, batch nll 0.780333, batch error rate 32.000000%\n",
      "At minibatch 35900, batch loss 0.898994, batch nll 0.663370, batch error rate 32.000000%\n",
      "At minibatch 36000, batch loss 0.923047, batch nll 0.687486, batch error rate 24.000000%\n",
      "At minibatch 36100, batch loss 0.721981, batch nll 0.486528, batch error rate 20.000000%\n",
      "At minibatch 36200, batch loss 0.831901, batch nll 0.596582, batch error rate 24.000000%\n",
      "At minibatch 36300, batch loss 0.897907, batch nll 0.662454, batch error rate 16.000000%\n",
      "At minibatch 36400, batch loss 0.815423, batch nll 0.579976, batch error rate 16.000000%\n",
      "At minibatch 36500, batch loss 0.902407, batch nll 0.667139, batch error rate 28.000000%\n",
      "At minibatch 36600, batch loss 1.116054, batch nll 0.880852, batch error rate 20.000000%\n",
      "At minibatch 36700, batch loss 1.174179, batch nll 0.938943, batch error rate 28.000000%\n",
      "At minibatch 36800, batch loss 1.107910, batch nll 0.872914, batch error rate 32.000000%\n",
      "After epoch 23: valid_err_rate: 23.090000% currently going to do 35 epochs\n",
      "After epoch 23: averaged train_err_rate: 26.790000% averaged train nll: 0.772610 averaged train loss: 1.007936\n",
      "At minibatch 36900, batch loss 0.880540, batch nll 0.645415, batch error rate 28.000000%\n",
      "At minibatch 37000, batch loss 0.930470, batch nll 0.695346, batch error rate 24.000000%\n",
      "At minibatch 37100, batch loss 0.616621, batch nll 0.381315, batch error rate 8.000000%\n",
      "At minibatch 37200, batch loss 0.979482, batch nll 0.744321, batch error rate 28.000000%\n",
      "At minibatch 37300, batch loss 0.985054, batch nll 0.749943, batch error rate 28.000000%\n",
      "At minibatch 37400, batch loss 1.197603, batch nll 0.962334, batch error rate 36.000000%\n",
      "At minibatch 37500, batch loss 1.144483, batch nll 0.909359, batch error rate 24.000000%\n",
      "At minibatch 37600, batch loss 0.917515, batch nll 0.682374, batch error rate 28.000000%\n",
      "At minibatch 37700, batch loss 1.114897, batch nll 0.879599, batch error rate 28.000000%\n",
      "At minibatch 37800, batch loss 0.794846, batch nll 0.559545, batch error rate 20.000000%\n",
      "At minibatch 37900, batch loss 0.983567, batch nll 0.748240, batch error rate 28.000000%\n",
      "At minibatch 38000, batch loss 0.859250, batch nll 0.623914, batch error rate 16.000000%\n",
      "At minibatch 38100, batch loss 1.127408, batch nll 0.892263, batch error rate 24.000000%\n",
      "At minibatch 38200, batch loss 0.941651, batch nll 0.706453, batch error rate 24.000000%\n",
      "At minibatch 38300, batch loss 0.731423, batch nll 0.496262, batch error rate 12.000000%\n",
      "At minibatch 38400, batch loss 0.975343, batch nll 0.740077, batch error rate 32.000000%\n",
      "After epoch 24: valid_err_rate: 25.160000% currently going to do 35 epochs\n",
      "After epoch 24: averaged train_err_rate: 26.575000% averaged train nll: 0.768099 averaged train loss: 1.003311\n",
      "At minibatch 38500, batch loss 0.829528, batch nll 0.594322, batch error rate 24.000000%\n",
      "At minibatch 38600, batch loss 0.834762, batch nll 0.599560, batch error rate 24.000000%\n",
      "At minibatch 38700, batch loss 1.086194, batch nll 0.850965, batch error rate 32.000000%\n",
      "At minibatch 38800, batch loss 1.006420, batch nll 0.771091, batch error rate 24.000000%\n",
      "At minibatch 38900, batch loss 1.294556, batch nll 1.058930, batch error rate 28.000000%\n",
      "At minibatch 39000, batch loss 0.726974, batch nll 0.491286, batch error rate 12.000000%\n",
      "At minibatch 39100, batch loss 1.242654, batch nll 1.007140, batch error rate 36.000000%\n",
      "At minibatch 39200, batch loss 0.994175, batch nll 0.758674, batch error rate 28.000000%\n",
      "At minibatch 39300, batch loss 0.959764, batch nll 0.724128, batch error rate 20.000000%\n",
      "At minibatch 39400, batch loss 0.792673, batch nll 0.557132, batch error rate 20.000000%\n",
      "At minibatch 39500, batch loss 1.080243, batch nll 0.844734, batch error rate 36.000000%\n",
      "At minibatch 39600, batch loss 0.782638, batch nll 0.547121, batch error rate 20.000000%\n",
      "At minibatch 39700, batch loss 1.094552, batch nll 0.859016, batch error rate 28.000000%\n",
      "At minibatch 39800, batch loss 0.721101, batch nll 0.485457, batch error rate 20.000000%\n",
      "At minibatch 39900, batch loss 1.006528, batch nll 0.770779, batch error rate 24.000000%\n",
      "At minibatch 40000, batch loss 1.060577, batch nll 0.824880, batch error rate 16.000000%\n",
      "After epoch 25: valid_err_rate: 22.890000% currently going to do 38 epochs\n",
      "After epoch 25: averaged train_err_rate: 26.802500% averaged train nll: 0.763653 averaged train loss: 0.999158\n",
      "At minibatch 40100, batch loss 1.025412, batch nll 0.789751, batch error rate 32.000000%\n",
      "At minibatch 40200, batch loss 1.135984, batch nll 0.900116, batch error rate 24.000000%\n",
      "At minibatch 40300, batch loss 1.189158, batch nll 0.953324, batch error rate 28.000000%\n",
      "At minibatch 40400, batch loss 0.961322, batch nll 0.725575, batch error rate 28.000000%\n",
      "At minibatch 40500, batch loss 1.100780, batch nll 0.865109, batch error rate 28.000000%\n",
      "At minibatch 40600, batch loss 0.894241, batch nll 0.658503, batch error rate 24.000000%\n",
      "At minibatch 40700, batch loss 1.460487, batch nll 1.224696, batch error rate 44.000000%\n",
      "At minibatch 40800, batch loss 0.824646, batch nll 0.588986, batch error rate 16.000000%\n",
      "At minibatch 40900, batch loss 0.735462, batch nll 0.499756, batch error rate 16.000000%\n",
      "At minibatch 41000, batch loss 1.048095, batch nll 0.812345, batch error rate 32.000000%\n",
      "At minibatch 41100, batch loss 0.857143, batch nll 0.621337, batch error rate 24.000000%\n",
      "At minibatch 41200, batch loss 1.142088, batch nll 0.906199, batch error rate 24.000000%\n",
      "At minibatch 41300, batch loss 0.977460, batch nll 0.741690, batch error rate 24.000000%\n",
      "At minibatch 41400, batch loss 1.207300, batch nll 0.971577, batch error rate 44.000000%\n",
      "At minibatch 41500, batch loss 0.899971, batch nll 0.664343, batch error rate 24.000000%\n",
      "At minibatch 41600, batch loss 0.904561, batch nll 0.668752, batch error rate 16.000000%\n",
      "After epoch 26: valid_err_rate: 23.530000% currently going to do 38 epochs\n",
      "After epoch 26: averaged train_err_rate: 26.182500% averaged train nll: 0.751068 averaged train loss: 0.986809\n",
      "At minibatch 41700, batch loss 0.934545, batch nll 0.698716, batch error rate 20.000000%\n",
      "At minibatch 41800, batch loss 1.079195, batch nll 0.843453, batch error rate 40.000000%\n",
      "At minibatch 41900, batch loss 0.837801, batch nll 0.601964, batch error rate 8.000000%\n",
      "At minibatch 42000, batch loss 0.913696, batch nll 0.677759, batch error rate 24.000000%\n",
      "At minibatch 42100, batch loss 1.193297, batch nll 0.957422, batch error rate 28.000000%\n",
      "At minibatch 42200, batch loss 0.752105, batch nll 0.516340, batch error rate 16.000000%\n",
      "At minibatch 42300, batch loss 0.794806, batch nll 0.559158, batch error rate 20.000000%\n",
      "At minibatch 42400, batch loss 0.931425, batch nll 0.695795, batch error rate 24.000000%\n",
      "At minibatch 42500, batch loss 1.129216, batch nll 0.893420, batch error rate 28.000000%\n",
      "At minibatch 42600, batch loss 0.896181, batch nll 0.660388, batch error rate 24.000000%\n",
      "At minibatch 42700, batch loss 1.015482, batch nll 0.779693, batch error rate 28.000000%\n",
      "At minibatch 42800, batch loss 1.075078, batch nll 0.839190, batch error rate 36.000000%\n",
      "At minibatch 42900, batch loss 0.947687, batch nll 0.711795, batch error rate 32.000000%\n",
      "At minibatch 43000, batch loss 0.846589, batch nll 0.610636, batch error rate 20.000000%\n",
      "At minibatch 43100, batch loss 1.087113, batch nll 0.851174, batch error rate 28.000000%\n",
      "At minibatch 43200, batch loss 1.185940, batch nll 0.950033, batch error rate 36.000000%\n",
      "After epoch 27: valid_err_rate: 23.560000% currently going to do 38 epochs\n",
      "After epoch 27: averaged train_err_rate: 25.987500% averaged train nll: 0.750289 averaged train loss: 0.986132\n",
      "At minibatch 43300, batch loss 1.090789, batch nll 0.854731, batch error rate 40.000000%\n",
      "At minibatch 43400, batch loss 0.753443, batch nll 0.517377, batch error rate 16.000000%\n",
      "At minibatch 43500, batch loss 0.721928, batch nll 0.485616, batch error rate 20.000000%\n",
      "At minibatch 43600, batch loss 1.196417, batch nll 0.960063, batch error rate 40.000000%\n",
      "At minibatch 43700, batch loss 1.014019, batch nll 0.777723, batch error rate 32.000000%\n",
      "At minibatch 43800, batch loss 0.930807, batch nll 0.694513, batch error rate 24.000000%\n",
      "At minibatch 43900, batch loss 0.895806, batch nll 0.659528, batch error rate 16.000000%\n",
      "At minibatch 44000, batch loss 1.115633, batch nll 0.879340, batch error rate 44.000000%\n",
      "At minibatch 44100, batch loss 1.381380, batch nll 1.145135, batch error rate 24.000000%\n",
      "At minibatch 44200, batch loss 0.876830, batch nll 0.640675, batch error rate 20.000000%\n",
      "At minibatch 44300, batch loss 0.848101, batch nll 0.611923, batch error rate 32.000000%\n",
      "At minibatch 44400, batch loss 0.935758, batch nll 0.699621, batch error rate 20.000000%\n",
      "At minibatch 44500, batch loss 1.141732, batch nll 0.905591, batch error rate 24.000000%\n",
      "At minibatch 44600, batch loss 1.592833, batch nll 1.356560, batch error rate 44.000000%\n",
      "At minibatch 44700, batch loss 1.280266, batch nll 1.043983, batch error rate 36.000000%\n",
      "At minibatch 44800, batch loss 0.883105, batch nll 0.646826, batch error rate 24.000000%\n",
      "After epoch 28: valid_err_rate: 23.000000% currently going to do 38 epochs\n",
      "After epoch 28: averaged train_err_rate: 25.922500% averaged train nll: 0.743900 averaged train loss: 0.980131\n",
      "At minibatch 44900, batch loss 0.941447, batch nll 0.704948, batch error rate 24.000000%\n",
      "At minibatch 45000, batch loss 1.205986, batch nll 0.969425, batch error rate 40.000000%\n",
      "At minibatch 45100, batch loss 1.211403, batch nll 0.974777, batch error rate 32.000000%\n",
      "At minibatch 45200, batch loss 1.426892, batch nll 1.190189, batch error rate 44.000000%\n",
      "At minibatch 45300, batch loss 1.013854, batch nll 0.777136, batch error rate 28.000000%\n",
      "At minibatch 45400, batch loss 0.844024, batch nll 0.607217, batch error rate 12.000000%\n",
      "At minibatch 45500, batch loss 1.074755, batch nll 0.837993, batch error rate 36.000000%\n",
      "At minibatch 45600, batch loss 0.803957, batch nll 0.567221, batch error rate 36.000000%\n",
      "At minibatch 45700, batch loss 0.943123, batch nll 0.706447, batch error rate 24.000000%\n",
      "At minibatch 45800, batch loss 1.026034, batch nll 0.789306, batch error rate 16.000000%\n",
      "At minibatch 45900, batch loss 0.836853, batch nll 0.600185, batch error rate 20.000000%\n",
      "At minibatch 46000, batch loss 1.190401, batch nll 0.953695, batch error rate 40.000000%\n",
      "At minibatch 46100, batch loss 0.976442, batch nll 0.739694, batch error rate 32.000000%\n",
      "At minibatch 46200, batch loss 1.300930, batch nll 1.064259, batch error rate 44.000000%\n",
      "At minibatch 46300, batch loss 1.057947, batch nll 0.821151, batch error rate 32.000000%\n",
      "At minibatch 46400, batch loss 1.095178, batch nll 0.858348, batch error rate 24.000000%\n",
      "After epoch 29: valid_err_rate: 22.930000% currently going to do 38 epochs\n",
      "After epoch 29: averaged train_err_rate: 25.612500% averaged train nll: 0.738686 averaged train loss: 0.975366\n",
      "At minibatch 46500, batch loss 0.833970, batch nll 0.597204, batch error rate 12.000000%\n",
      "At minibatch 46600, batch loss 0.725757, batch nll 0.488978, batch error rate 16.000000%\n",
      "At minibatch 46700, batch loss 1.170133, batch nll 0.933271, batch error rate 28.000000%\n",
      "At minibatch 46800, batch loss 0.567940, batch nll 0.331030, batch error rate 8.000000%\n",
      "At minibatch 46900, batch loss 1.108136, batch nll 0.871314, batch error rate 24.000000%\n",
      "At minibatch 47000, batch loss 0.798448, batch nll 0.561690, batch error rate 12.000000%\n",
      "At minibatch 47100, batch loss 0.915898, batch nll 0.679074, batch error rate 24.000000%\n",
      "At minibatch 47200, batch loss 0.678702, batch nll 0.441947, batch error rate 8.000000%\n",
      "At minibatch 47300, batch loss 1.372283, batch nll 1.135399, batch error rate 48.000000%\n",
      "At minibatch 47400, batch loss 0.952168, batch nll 0.715247, batch error rate 28.000000%\n",
      "At minibatch 47500, batch loss 0.811222, batch nll 0.574357, batch error rate 20.000000%\n",
      "At minibatch 47600, batch loss 0.919792, batch nll 0.682978, batch error rate 28.000000%\n",
      "At minibatch 47700, batch loss 0.894435, batch nll 0.657596, batch error rate 16.000000%\n",
      "At minibatch 47800, batch loss 0.913132, batch nll 0.676208, batch error rate 24.000000%\n",
      "At minibatch 47900, batch loss 1.082462, batch nll 0.845544, batch error rate 40.000000%\n",
      "At minibatch 48000, batch loss 0.639821, batch nll 0.402900, batch error rate 12.000000%\n",
      "After epoch 30: valid_err_rate: 22.350000% currently going to do 46 epochs\n",
      "After epoch 30: averaged train_err_rate: 25.602500% averaged train nll: 0.737023 averaged train loss: 0.973872\n",
      "At minibatch 48100, batch loss 1.321917, batch nll 1.084989, batch error rate 40.000000%\n",
      "At minibatch 48200, batch loss 0.848104, batch nll 0.611142, batch error rate 24.000000%\n",
      "At minibatch 48300, batch loss 1.093304, batch nll 0.856552, batch error rate 20.000000%\n",
      "At minibatch 48400, batch loss 0.696733, batch nll 0.459915, batch error rate 16.000000%\n",
      "At minibatch 48500, batch loss 0.877438, batch nll 0.640631, batch error rate 24.000000%\n",
      "At minibatch 48600, batch loss 0.683892, batch nll 0.446836, batch error rate 12.000000%\n",
      "At minibatch 48700, batch loss 1.220499, batch nll 0.983478, batch error rate 28.000000%\n",
      "At minibatch 48800, batch loss 1.235095, batch nll 0.998070, batch error rate 24.000000%\n",
      "At minibatch 48900, batch loss 0.946853, batch nll 0.709887, batch error rate 32.000000%\n",
      "At minibatch 49000, batch loss 1.048549, batch nll 0.811497, batch error rate 24.000000%\n",
      "At minibatch 49100, batch loss 0.831364, batch nll 0.594312, batch error rate 20.000000%\n",
      "At minibatch 49200, batch loss 1.082112, batch nll 0.845035, batch error rate 32.000000%\n",
      "At minibatch 49300, batch loss 0.990748, batch nll 0.753690, batch error rate 20.000000%\n",
      "At minibatch 49400, batch loss 0.718740, batch nll 0.481567, batch error rate 20.000000%\n",
      "At minibatch 49500, batch loss 1.419204, batch nll 1.182007, batch error rate 44.000000%\n",
      "At minibatch 49600, batch loss 0.807111, batch nll 0.569988, batch error rate 12.000000%\n",
      "After epoch 31: valid_err_rate: 22.910000% currently going to do 46 epochs\n",
      "After epoch 31: averaged train_err_rate: 25.780000% averaged train nll: 0.736544 averaged train loss: 0.973534\n",
      "At minibatch 49700, batch loss 0.745250, batch nll 0.508159, batch error rate 16.000000%\n",
      "At minibatch 49800, batch loss 1.083838, batch nll 0.846731, batch error rate 20.000000%\n",
      "At minibatch 49900, batch loss 1.041280, batch nll 0.804101, batch error rate 28.000000%\n",
      "At minibatch 50000, batch loss 0.942316, batch nll 0.705197, batch error rate 20.000000%\n",
      "At minibatch 50100, batch loss 0.894267, batch nll 0.657149, batch error rate 24.000000%\n",
      "At minibatch 50200, batch loss 1.071928, batch nll 0.834645, batch error rate 36.000000%\n",
      "At minibatch 50300, batch loss 1.115983, batch nll 0.878769, batch error rate 20.000000%\n",
      "At minibatch 50400, batch loss 1.226074, batch nll 0.988881, batch error rate 32.000000%\n",
      "At minibatch 50500, batch loss 0.919452, batch nll 0.682232, batch error rate 24.000000%\n",
      "At minibatch 50600, batch loss 0.964611, batch nll 0.727415, batch error rate 24.000000%\n",
      "At minibatch 50700, batch loss 1.360934, batch nll 1.123625, batch error rate 32.000000%\n",
      "At minibatch 50800, batch loss 0.986667, batch nll 0.749457, batch error rate 32.000000%\n",
      "At minibatch 50900, batch loss 1.270845, batch nll 1.033662, batch error rate 36.000000%\n",
      "At minibatch 51000, batch loss 1.015431, batch nll 0.778144, batch error rate 24.000000%\n",
      "At minibatch 51100, batch loss 0.839570, batch nll 0.602229, batch error rate 12.000000%\n",
      "At minibatch 51200, batch loss 0.830791, batch nll 0.593356, batch error rate 16.000000%\n",
      "After epoch 32: valid_err_rate: 23.640000% currently going to do 46 epochs\n",
      "After epoch 32: averaged train_err_rate: 25.177500% averaged train nll: 0.731680 averaged train loss: 0.968890\n",
      "At minibatch 51300, batch loss 0.824609, batch nll 0.587199, batch error rate 16.000000%\n",
      "At minibatch 51400, batch loss 1.087860, batch nll 0.850338, batch error rate 28.000000%\n",
      "At minibatch 51500, batch loss 0.975213, batch nll 0.737651, batch error rate 28.000000%\n",
      "At minibatch 51600, batch loss 0.762651, batch nll 0.524873, batch error rate 16.000000%\n",
      "At minibatch 51700, batch loss 1.124263, batch nll 0.886532, batch error rate 28.000000%\n",
      "At minibatch 51800, batch loss 1.113548, batch nll 0.875669, batch error rate 44.000000%\n",
      "At minibatch 51900, batch loss 0.787139, batch nll 0.549251, batch error rate 16.000000%\n",
      "At minibatch 52000, batch loss 0.810521, batch nll 0.572817, batch error rate 16.000000%\n",
      "At minibatch 52100, batch loss 0.920620, batch nll 0.683002, batch error rate 20.000000%\n",
      "At minibatch 52200, batch loss 0.761040, batch nll 0.523356, batch error rate 16.000000%\n",
      "At minibatch 52300, batch loss 1.223799, batch nll 0.986058, batch error rate 32.000000%\n",
      "At minibatch 52400, batch loss 0.908095, batch nll 0.670352, batch error rate 24.000000%\n",
      "At minibatch 52500, batch loss 0.837981, batch nll 0.600258, batch error rate 24.000000%\n",
      "At minibatch 52600, batch loss 0.904976, batch nll 0.667275, batch error rate 24.000000%\n",
      "At minibatch 52700, batch loss 1.175417, batch nll 0.937685, batch error rate 32.000000%\n",
      "At minibatch 52800, batch loss 1.286383, batch nll 1.048651, batch error rate 40.000000%\n",
      "After epoch 33: valid_err_rate: 22.820000% currently going to do 46 epochs\n",
      "After epoch 33: averaged train_err_rate: 25.470000% averaged train nll: 0.728633 averaged train loss: 0.966321\n",
      "At minibatch 52900, batch loss 1.180649, batch nll 0.942711, batch error rate 40.000000%\n",
      "At minibatch 53000, batch loss 1.524244, batch nll 1.286342, batch error rate 36.000000%\n",
      "At minibatch 53100, batch loss 0.620611, batch nll 0.382668, batch error rate 12.000000%\n",
      "At minibatch 53200, batch loss 1.125331, batch nll 0.887370, batch error rate 28.000000%\n",
      "At minibatch 53300, batch loss 1.496292, batch nll 1.258428, batch error rate 40.000000%\n",
      "At minibatch 53400, batch loss 0.968184, batch nll 0.730315, batch error rate 32.000000%\n",
      "At minibatch 53500, batch loss 0.916129, batch nll 0.678086, batch error rate 24.000000%\n",
      "At minibatch 53600, batch loss 1.086481, batch nll 0.848366, batch error rate 32.000000%\n",
      "At minibatch 53700, batch loss 1.149005, batch nll 0.911080, batch error rate 32.000000%\n",
      "At minibatch 53800, batch loss 0.883151, batch nll 0.645309, batch error rate 28.000000%\n",
      "At minibatch 53900, batch loss 0.546507, batch nll 0.308513, batch error rate 12.000000%\n",
      "At minibatch 54000, batch loss 1.244747, batch nll 1.006793, batch error rate 40.000000%\n",
      "At minibatch 54100, batch loss 0.996014, batch nll 0.758011, batch error rate 32.000000%\n",
      "At minibatch 54200, batch loss 1.497760, batch nll 1.259700, batch error rate 44.000000%\n",
      "At minibatch 54300, batch loss 0.804822, batch nll 0.566853, batch error rate 24.000000%\n",
      "At minibatch 54400, batch loss 0.814354, batch nll 0.576356, batch error rate 20.000000%\n",
      "After epoch 34: valid_err_rate: 22.880000% currently going to do 46 epochs\n",
      "After epoch 34: averaged train_err_rate: 25.030000% averaged train nll: 0.724162 averaged train loss: 0.962117\n",
      "At minibatch 54500, batch loss 0.901732, batch nll 0.663723, batch error rate 28.000000%\n",
      "At minibatch 54600, batch loss 1.033126, batch nll 0.795127, batch error rate 28.000000%\n",
      "At minibatch 54700, batch loss 1.102826, batch nll 0.864721, batch error rate 32.000000%\n",
      "At minibatch 54800, batch loss 0.925138, batch nll 0.686909, batch error rate 16.000000%\n",
      "At minibatch 54900, batch loss 1.170086, batch nll 0.931909, batch error rate 24.000000%\n",
      "At minibatch 55000, batch loss 0.666748, batch nll 0.428651, batch error rate 12.000000%\n",
      "At minibatch 55100, batch loss 1.077946, batch nll 0.839901, batch error rate 24.000000%\n",
      "At minibatch 55200, batch loss 1.008920, batch nll 0.770785, batch error rate 36.000000%\n",
      "At minibatch 55300, batch loss 0.690219, batch nll 0.451955, batch error rate 16.000000%\n",
      "At minibatch 55400, batch loss 1.150522, batch nll 0.912272, batch error rate 36.000000%\n",
      "At minibatch 55500, batch loss 1.030102, batch nll 0.791798, batch error rate 32.000000%\n",
      "At minibatch 55600, batch loss 0.857335, batch nll 0.619029, batch error rate 24.000000%\n",
      "At minibatch 55700, batch loss 0.786677, batch nll 0.548218, batch error rate 24.000000%\n",
      "At minibatch 55800, batch loss 0.881194, batch nll 0.642704, batch error rate 24.000000%\n",
      "At minibatch 55900, batch loss 0.769935, batch nll 0.531543, batch error rate 24.000000%\n",
      "At minibatch 56000, batch loss 1.008081, batch nll 0.769611, batch error rate 24.000000%\n",
      "After epoch 35: valid_err_rate: 22.360000% currently going to do 46 epochs\n",
      "After epoch 35: averaged train_err_rate: 24.990000% averaged train nll: 0.720911 averaged train loss: 0.959140\n",
      "At minibatch 56100, batch loss 0.986530, batch nll 0.748079, batch error rate 32.000000%\n",
      "At minibatch 56200, batch loss 1.214718, batch nll 0.976337, batch error rate 40.000000%\n",
      "At minibatch 56300, batch loss 1.117515, batch nll 0.879121, batch error rate 36.000000%\n",
      "At minibatch 56400, batch loss 0.974115, batch nll 0.735707, batch error rate 20.000000%\n",
      "At minibatch 56500, batch loss 1.049084, batch nll 0.810723, batch error rate 40.000000%\n",
      "At minibatch 56600, batch loss 1.098260, batch nll 0.859922, batch error rate 28.000000%\n",
      "At minibatch 56700, batch loss 0.938652, batch nll 0.700429, batch error rate 16.000000%\n",
      "At minibatch 56800, batch loss 0.955221, batch nll 0.716970, batch error rate 36.000000%\n",
      "At minibatch 56900, batch loss 1.280855, batch nll 1.042496, batch error rate 28.000000%\n",
      "At minibatch 57000, batch loss 0.900729, batch nll 0.662394, batch error rate 24.000000%\n",
      "At minibatch 57100, batch loss 0.909997, batch nll 0.671570, batch error rate 20.000000%\n",
      "At minibatch 57200, batch loss 0.751212, batch nll 0.512702, batch error rate 24.000000%\n",
      "At minibatch 57300, batch loss 1.308450, batch nll 1.070044, batch error rate 32.000000%\n",
      "At minibatch 57400, batch loss 1.051017, batch nll 0.812580, batch error rate 32.000000%\n",
      "At minibatch 57500, batch loss 1.069677, batch nll 0.831231, batch error rate 28.000000%\n",
      "At minibatch 57600, batch loss 1.163967, batch nll 0.925572, batch error rate 32.000000%\n",
      "After epoch 36: valid_err_rate: 22.380000% currently going to do 46 epochs\n",
      "After epoch 36: averaged train_err_rate: 25.090000% averaged train nll: 0.724221 averaged train loss: 0.962600\n",
      "At minibatch 57700, batch loss 0.997103, batch nll 0.758601, batch error rate 24.000000%\n",
      "At minibatch 57800, batch loss 0.851421, batch nll 0.612874, batch error rate 28.000000%\n",
      "At minibatch 57900, batch loss 1.256908, batch nll 1.018358, batch error rate 48.000000%\n",
      "At minibatch 58000, batch loss 1.185369, batch nll 0.946753, batch error rate 28.000000%\n",
      "At minibatch 58100, batch loss 0.883228, batch nll 0.644602, batch error rate 28.000000%\n",
      "At minibatch 58200, batch loss 0.692195, batch nll 0.453596, batch error rate 20.000000%\n",
      "At minibatch 58300, batch loss 0.861548, batch nll 0.622848, batch error rate 24.000000%\n",
      "At minibatch 58400, batch loss 0.843111, batch nll 0.604536, batch error rate 24.000000%\n",
      "At minibatch 58500, batch loss 1.228010, batch nll 0.989433, batch error rate 32.000000%\n",
      "At minibatch 58600, batch loss 0.904600, batch nll 0.666003, batch error rate 32.000000%\n",
      "At minibatch 58700, batch loss 0.837410, batch nll 0.598915, batch error rate 20.000000%\n",
      "At minibatch 58800, batch loss 0.650486, batch nll 0.411953, batch error rate 8.000000%\n",
      "At minibatch 58900, batch loss 1.076935, batch nll 0.838337, batch error rate 40.000000%\n",
      "At minibatch 59000, batch loss 1.060662, batch nll 0.821977, batch error rate 28.000000%\n",
      "At minibatch 59100, batch loss 0.919283, batch nll 0.680666, batch error rate 24.000000%\n",
      "At minibatch 59200, batch loss 0.975315, batch nll 0.736669, batch error rate 20.000000%\n",
      "After epoch 37: valid_err_rate: 22.170000% currently going to do 56 epochs\n",
      "After epoch 37: averaged train_err_rate: 24.547500% averaged train nll: 0.713213 averaged train loss: 0.951808\n",
      "At minibatch 59300, batch loss 1.122069, batch nll 0.883357, batch error rate 24.000000%\n",
      "At minibatch 59400, batch loss 0.977065, batch nll 0.738280, batch error rate 24.000000%\n",
      "At minibatch 59500, batch loss 1.162866, batch nll 0.924053, batch error rate 32.000000%\n",
      "At minibatch 59600, batch loss 0.928847, batch nll 0.690050, batch error rate 28.000000%\n",
      "At minibatch 59700, batch loss 1.444226, batch nll 1.205443, batch error rate 24.000000%\n",
      "At minibatch 59800, batch loss 0.782961, batch nll 0.544151, batch error rate 12.000000%\n",
      "At minibatch 59900, batch loss 0.922120, batch nll 0.683195, batch error rate 20.000000%\n",
      "At minibatch 60000, batch loss 0.837952, batch nll 0.599081, batch error rate 16.000000%\n",
      "At minibatch 60100, batch loss 0.920299, batch nll 0.681279, batch error rate 24.000000%\n",
      "At minibatch 60200, batch loss 1.023337, batch nll 0.784368, batch error rate 16.000000%\n",
      "At minibatch 60300, batch loss 0.923003, batch nll 0.683953, batch error rate 28.000000%\n",
      "At minibatch 60400, batch loss 1.183923, batch nll 0.944903, batch error rate 44.000000%\n",
      "At minibatch 60500, batch loss 1.033252, batch nll 0.794147, batch error rate 32.000000%\n",
      "At minibatch 60600, batch loss 0.718424, batch nll 0.479352, batch error rate 16.000000%\n",
      "At minibatch 60700, batch loss 0.672060, batch nll 0.432976, batch error rate 8.000000%\n",
      "At minibatch 60800, batch loss 0.837316, batch nll 0.598278, batch error rate 20.000000%\n",
      "After epoch 38: valid_err_rate: 21.460000% currently going to do 58 epochs\n",
      "After epoch 38: averaged train_err_rate: 24.527500% averaged train nll: 0.706005 averaged train loss: 0.944919\n",
      "At minibatch 60900, batch loss 0.657778, batch nll 0.418620, batch error rate 12.000000%\n",
      "At minibatch 61000, batch loss 1.100607, batch nll 0.861451, batch error rate 28.000000%\n",
      "At minibatch 61100, batch loss 1.097327, batch nll 0.858081, batch error rate 24.000000%\n",
      "At minibatch 61200, batch loss 0.762185, batch nll 0.522878, batch error rate 16.000000%\n",
      "At minibatch 61300, batch loss 0.690287, batch nll 0.450973, batch error rate 24.000000%\n",
      "At minibatch 61400, batch loss 1.146874, batch nll 0.907707, batch error rate 32.000000%\n",
      "At minibatch 61500, batch loss 1.046572, batch nll 0.807313, batch error rate 36.000000%\n",
      "At minibatch 61600, batch loss 1.061477, batch nll 0.822140, batch error rate 28.000000%\n",
      "At minibatch 61700, batch loss 1.064700, batch nll 0.825456, batch error rate 32.000000%\n",
      "At minibatch 61800, batch loss 0.983727, batch nll 0.744348, batch error rate 28.000000%\n",
      "At minibatch 61900, batch loss 0.941319, batch nll 0.701926, batch error rate 28.000000%\n",
      "At minibatch 62000, batch loss 1.107586, batch nll 0.868140, batch error rate 24.000000%\n",
      "At minibatch 62100, batch loss 0.994219, batch nll 0.754788, batch error rate 24.000000%\n",
      "At minibatch 62200, batch loss 0.864836, batch nll 0.625379, batch error rate 24.000000%\n",
      "At minibatch 62300, batch loss 0.823414, batch nll 0.583823, batch error rate 24.000000%\n",
      "At minibatch 62400, batch loss 1.103415, batch nll 0.863817, batch error rate 28.000000%\n",
      "After epoch 39: valid_err_rate: 22.750000% currently going to do 58 epochs\n",
      "After epoch 39: averaged train_err_rate: 24.477500% averaged train nll: 0.703476 averaged train loss: 0.942802\n",
      "At minibatch 62500, batch loss 0.950767, batch nll 0.711230, batch error rate 20.000000%\n",
      "At minibatch 62600, batch loss 0.956803, batch nll 0.717272, batch error rate 24.000000%\n",
      "At minibatch 62700, batch loss 1.171277, batch nll 0.931794, batch error rate 24.000000%\n",
      "At minibatch 62800, batch loss 1.057200, batch nll 0.817717, batch error rate 36.000000%\n",
      "At minibatch 62900, batch loss 0.937322, batch nll 0.697843, batch error rate 32.000000%\n",
      "At minibatch 63000, batch loss 1.076704, batch nll 0.837218, batch error rate 24.000000%\n",
      "At minibatch 63100, batch loss 0.656455, batch nll 0.416869, batch error rate 8.000000%\n",
      "At minibatch 63200, batch loss 0.721083, batch nll 0.481489, batch error rate 20.000000%\n",
      "At minibatch 63300, batch loss 1.116005, batch nll 0.876230, batch error rate 28.000000%\n",
      "At minibatch 63400, batch loss 0.698159, batch nll 0.458503, batch error rate 20.000000%\n",
      "At minibatch 63500, batch loss 1.150189, batch nll 0.910510, batch error rate 36.000000%\n",
      "At minibatch 63600, batch loss 0.985333, batch nll 0.745634, batch error rate 28.000000%\n",
      "At minibatch 63700, batch loss 0.877453, batch nll 0.637708, batch error rate 28.000000%\n",
      "At minibatch 63800, batch loss 0.831851, batch nll 0.592171, batch error rate 20.000000%\n",
      "At minibatch 63900, batch loss 0.871239, batch nll 0.631529, batch error rate 24.000000%\n",
      "At minibatch 64000, batch loss 0.995578, batch nll 0.755745, batch error rate 36.000000%\n",
      "After epoch 40: valid_err_rate: 21.950000% currently going to do 58 epochs\n",
      "After epoch 40: averaged train_err_rate: 24.377500% averaged train nll: 0.703893 averaged train loss: 0.943509\n",
      "At minibatch 64100, batch loss 0.920027, batch nll 0.680255, batch error rate 16.000000%\n",
      "At minibatch 64200, batch loss 1.052752, batch nll 0.812904, batch error rate 36.000000%\n",
      "At minibatch 64300, batch loss 0.793126, batch nll 0.553285, batch error rate 24.000000%\n",
      "At minibatch 64400, batch loss 0.957566, batch nll 0.717579, batch error rate 24.000000%\n",
      "At minibatch 64500, batch loss 0.861438, batch nll 0.621406, batch error rate 28.000000%\n",
      "At minibatch 64600, batch loss 0.934113, batch nll 0.693994, batch error rate 28.000000%\n",
      "At minibatch 64700, batch loss 0.627806, batch nll 0.387697, batch error rate 4.000000%\n",
      "At minibatch 64800, batch loss 1.070654, batch nll 0.830576, batch error rate 16.000000%\n",
      "At minibatch 64900, batch loss 1.303381, batch nll 1.063223, batch error rate 44.000000%\n",
      "At minibatch 65000, batch loss 1.044769, batch nll 0.804583, batch error rate 32.000000%\n",
      "At minibatch 65100, batch loss 0.801821, batch nll 0.561656, batch error rate 16.000000%\n",
      "At minibatch 65200, batch loss 1.003118, batch nll 0.762967, batch error rate 32.000000%\n",
      "At minibatch 65300, batch loss 0.968367, batch nll 0.728211, batch error rate 24.000000%\n",
      "At minibatch 65400, batch loss 0.971057, batch nll 0.730860, batch error rate 28.000000%\n",
      "At minibatch 65500, batch loss 1.402861, batch nll 1.162579, batch error rate 48.000000%\n",
      "At minibatch 65600, batch loss 0.922416, batch nll 0.682171, batch error rate 20.000000%\n",
      "After epoch 41: valid_err_rate: 21.530000% currently going to do 58 epochs\n",
      "After epoch 41: averaged train_err_rate: 24.260000% averaged train nll: 0.698894 averaged train loss: 0.938958\n",
      "At minibatch 65700, batch loss 1.033808, batch nll 0.793673, batch error rate 20.000000%\n",
      "At minibatch 65800, batch loss 0.769222, batch nll 0.528958, batch error rate 24.000000%\n",
      "At minibatch 65900, batch loss 0.942629, batch nll 0.702345, batch error rate 24.000000%\n",
      "At minibatch 66000, batch loss 0.953479, batch nll 0.713140, batch error rate 28.000000%\n",
      "At minibatch 66100, batch loss 0.898288, batch nll 0.657847, batch error rate 24.000000%\n",
      "At minibatch 66200, batch loss 0.878982, batch nll 0.638591, batch error rate 32.000000%\n",
      "At minibatch 66300, batch loss 1.072016, batch nll 0.831560, batch error rate 36.000000%\n",
      "At minibatch 66400, batch loss 0.844121, batch nll 0.603735, batch error rate 24.000000%\n",
      "At minibatch 66500, batch loss 0.903374, batch nll 0.662913, batch error rate 20.000000%\n",
      "At minibatch 66600, batch loss 0.886830, batch nll 0.646347, batch error rate 16.000000%\n",
      "At minibatch 66700, batch loss 0.706065, batch nll 0.465593, batch error rate 20.000000%\n",
      "At minibatch 66800, batch loss 0.962866, batch nll 0.722432, batch error rate 36.000000%\n",
      "At minibatch 66900, batch loss 1.163115, batch nll 0.922661, batch error rate 20.000000%\n",
      "At minibatch 67000, batch loss 0.764650, batch nll 0.524125, batch error rate 20.000000%\n",
      "At minibatch 67100, batch loss 1.192684, batch nll 0.952116, batch error rate 32.000000%\n",
      "At minibatch 67200, batch loss 0.721451, batch nll 0.480937, batch error rate 20.000000%\n",
      "After epoch 42: valid_err_rate: 22.760000% currently going to do 58 epochs\n",
      "After epoch 42: averaged train_err_rate: 24.150000% averaged train nll: 0.696945 averaged train loss: 0.937350\n",
      "At minibatch 67300, batch loss 0.916611, batch nll 0.675973, batch error rate 20.000000%\n",
      "At minibatch 67400, batch loss 0.730860, batch nll 0.490242, batch error rate 16.000000%\n",
      "At minibatch 67500, batch loss 0.898417, batch nll 0.657843, batch error rate 24.000000%\n",
      "At minibatch 67600, batch loss 1.203397, batch nll 0.962785, batch error rate 44.000000%\n",
      "At minibatch 67700, batch loss 0.786888, batch nll 0.546297, batch error rate 20.000000%\n",
      "At minibatch 67800, batch loss 0.661866, batch nll 0.421267, batch error rate 12.000000%\n",
      "At minibatch 67900, batch loss 0.847013, batch nll 0.606468, batch error rate 20.000000%\n",
      "At minibatch 68000, batch loss 0.888601, batch nll 0.647976, batch error rate 20.000000%\n",
      "At minibatch 68100, batch loss 0.828010, batch nll 0.587269, batch error rate 24.000000%\n",
      "At minibatch 68200, batch loss 0.702799, batch nll 0.462095, batch error rate 12.000000%\n",
      "At minibatch 68300, batch loss 0.994791, batch nll 0.754158, batch error rate 36.000000%\n",
      "At minibatch 68400, batch loss 0.909662, batch nll 0.669030, batch error rate 20.000000%\n",
      "At minibatch 68500, batch loss 1.105777, batch nll 0.865048, batch error rate 40.000000%\n",
      "At minibatch 68600, batch loss 0.642767, batch nll 0.402103, batch error rate 8.000000%\n",
      "At minibatch 68700, batch loss 1.092541, batch nll 0.851910, batch error rate 28.000000%\n",
      "At minibatch 68800, batch loss 1.080509, batch nll 0.839842, batch error rate 28.000000%\n",
      "After epoch 43: valid_err_rate: 21.700000% currently going to do 58 epochs\n",
      "After epoch 43: averaged train_err_rate: 24.077500% averaged train nll: 0.696759 averaged train loss: 0.937388\n",
      "At minibatch 68900, batch loss 0.922815, batch nll 0.682158, batch error rate 24.000000%\n",
      "At minibatch 69000, batch loss 1.394214, batch nll 1.153478, batch error rate 40.000000%\n",
      "At minibatch 69100, batch loss 1.160474, batch nll 0.919765, batch error rate 36.000000%\n",
      "At minibatch 69200, batch loss 1.024038, batch nll 0.783258, batch error rate 24.000000%\n",
      "At minibatch 69300, batch loss 0.796263, batch nll 0.555489, batch error rate 20.000000%\n",
      "At minibatch 69400, batch loss 1.033782, batch nll 0.793005, batch error rate 20.000000%\n",
      "At minibatch 69500, batch loss 1.005224, batch nll 0.764452, batch error rate 24.000000%\n",
      "At minibatch 69600, batch loss 0.982275, batch nll 0.741457, batch error rate 24.000000%\n",
      "At minibatch 69700, batch loss 1.437477, batch nll 1.196569, batch error rate 32.000000%\n",
      "At minibatch 69800, batch loss 1.120857, batch nll 0.879978, batch error rate 28.000000%\n",
      "At minibatch 69900, batch loss 0.956894, batch nll 0.715939, batch error rate 28.000000%\n",
      "At minibatch 70000, batch loss 0.909673, batch nll 0.668826, batch error rate 24.000000%\n",
      "At minibatch 70100, batch loss 0.660870, batch nll 0.420113, batch error rate 16.000000%\n",
      "At minibatch 70200, batch loss 1.052988, batch nll 0.812145, batch error rate 32.000000%\n",
      "At minibatch 70300, batch loss 0.998200, batch nll 0.757416, batch error rate 32.000000%\n",
      "At minibatch 70400, batch loss 0.849351, batch nll 0.608535, batch error rate 28.000000%\n",
      "After epoch 44: valid_err_rate: 22.270000% currently going to do 58 epochs\n",
      "After epoch 44: averaged train_err_rate: 24.080000% averaged train nll: 0.695548 averaged train loss: 0.936337\n",
      "At minibatch 70500, batch loss 1.224117, batch nll 0.983297, batch error rate 36.000000%\n",
      "At minibatch 70600, batch loss 1.387172, batch nll 1.146317, batch error rate 44.000000%\n",
      "At minibatch 70700, batch loss 0.969079, batch nll 0.728160, batch error rate 32.000000%\n",
      "At minibatch 70800, batch loss 1.209956, batch nll 0.969038, batch error rate 40.000000%\n",
      "At minibatch 70900, batch loss 1.000723, batch nll 0.759708, batch error rate 24.000000%\n",
      "At minibatch 71000, batch loss 0.770901, batch nll 0.529925, batch error rate 16.000000%\n",
      "At minibatch 71100, batch loss 0.978557, batch nll 0.737604, batch error rate 28.000000%\n",
      "At minibatch 71200, batch loss 0.898191, batch nll 0.657163, batch error rate 24.000000%\n",
      "At minibatch 71300, batch loss 0.851629, batch nll 0.610561, batch error rate 16.000000%\n",
      "At minibatch 71400, batch loss 1.204684, batch nll 0.963665, batch error rate 32.000000%\n",
      "At minibatch 71500, batch loss 0.948470, batch nll 0.707408, batch error rate 28.000000%\n",
      "At minibatch 71600, batch loss 0.874977, batch nll 0.633894, batch error rate 20.000000%\n",
      "At minibatch 71700, batch loss 1.230824, batch nll 0.989688, batch error rate 32.000000%\n",
      "At minibatch 71800, batch loss 1.056687, batch nll 0.815529, batch error rate 28.000000%\n",
      "At minibatch 71900, batch loss 0.717706, batch nll 0.476589, batch error rate 12.000000%\n",
      "At minibatch 72000, batch loss 0.942674, batch nll 0.701613, batch error rate 28.000000%\n",
      "After epoch 45: valid_err_rate: 21.700000% currently going to do 58 epochs\n",
      "After epoch 45: averaged train_err_rate: 24.167500% averaged train nll: 0.693357 averaged train loss: 0.934360\n",
      "At minibatch 72100, batch loss 0.848080, batch nll 0.607051, batch error rate 20.000000%\n",
      "At minibatch 72200, batch loss 0.755020, batch nll 0.513886, batch error rate 20.000000%\n",
      "At minibatch 72300, batch loss 0.754132, batch nll 0.512950, batch error rate 16.000000%\n",
      "At minibatch 72400, batch loss 0.990561, batch nll 0.749340, batch error rate 28.000000%\n",
      "At minibatch 72500, batch loss 0.863422, batch nll 0.622241, batch error rate 20.000000%\n",
      "At minibatch 72600, batch loss 0.653186, batch nll 0.411988, batch error rate 16.000000%\n",
      "At minibatch 72700, batch loss 0.941943, batch nll 0.700795, batch error rate 20.000000%\n",
      "At minibatch 72800, batch loss 0.897629, batch nll 0.656486, batch error rate 16.000000%\n",
      "At minibatch 72900, batch loss 1.385467, batch nll 1.144251, batch error rate 44.000000%\n",
      "At minibatch 73000, batch loss 1.146715, batch nll 0.905439, batch error rate 36.000000%\n",
      "At minibatch 73100, batch loss 0.841974, batch nll 0.600630, batch error rate 24.000000%\n",
      "At minibatch 73200, batch loss 0.920899, batch nll 0.679567, batch error rate 28.000000%\n",
      "At minibatch 73300, batch loss 0.965219, batch nll 0.723873, batch error rate 16.000000%\n",
      "At minibatch 73400, batch loss 0.850977, batch nll 0.609649, batch error rate 24.000000%\n",
      "At minibatch 73500, batch loss 0.940974, batch nll 0.699589, batch error rate 24.000000%\n",
      "At minibatch 73600, batch loss 0.846971, batch nll 0.605564, batch error rate 28.000000%\n",
      "After epoch 46: valid_err_rate: 22.120000% currently going to do 58 epochs\n",
      "After epoch 46: averaged train_err_rate: 24.135000% averaged train nll: 0.694052 averaged train loss: 0.935286\n",
      "At minibatch 73700, batch loss 0.784287, batch nll 0.542811, batch error rate 16.000000%\n",
      "At minibatch 73800, batch loss 0.860969, batch nll 0.619440, batch error rate 20.000000%\n",
      "At minibatch 73900, batch loss 0.872951, batch nll 0.631361, batch error rate 28.000000%\n",
      "At minibatch 74000, batch loss 0.709448, batch nll 0.467829, batch error rate 12.000000%\n",
      "At minibatch 74100, batch loss 1.009460, batch nll 0.767842, batch error rate 28.000000%\n",
      "At minibatch 74200, batch loss 0.593540, batch nll 0.351978, batch error rate 16.000000%\n",
      "At minibatch 74300, batch loss 1.044720, batch nll 0.803130, batch error rate 28.000000%\n",
      "At minibatch 74400, batch loss 0.864259, batch nll 0.622620, batch error rate 16.000000%\n",
      "At minibatch 74500, batch loss 1.236499, batch nll 0.994927, batch error rate 28.000000%\n",
      "At minibatch 74600, batch loss 0.676140, batch nll 0.434484, batch error rate 20.000000%\n",
      "At minibatch 74700, batch loss 0.961659, batch nll 0.719971, batch error rate 16.000000%\n",
      "At minibatch 74800, batch loss 1.043631, batch nll 0.801917, batch error rate 24.000000%\n",
      "At minibatch 74900, batch loss 0.837614, batch nll 0.595899, batch error rate 16.000000%\n",
      "At minibatch 75000, batch loss 0.938808, batch nll 0.697107, batch error rate 24.000000%\n",
      "At minibatch 75100, batch loss 0.678534, batch nll 0.436871, batch error rate 20.000000%\n",
      "At minibatch 75200, batch loss 0.805669, batch nll 0.564041, batch error rate 12.000000%\n",
      "After epoch 47: valid_err_rate: 21.260000% currently going to do 71 epochs\n",
      "After epoch 47: averaged train_err_rate: 23.892500% averaged train nll: 0.689050 averaged train loss: 0.930662\n",
      "At minibatch 75300, batch loss 0.869472, batch nll 0.627799, batch error rate 20.000000%\n",
      "At minibatch 75400, batch loss 1.079203, batch nll 0.837594, batch error rate 32.000000%\n",
      "At minibatch 75500, batch loss 0.772720, batch nll 0.531066, batch error rate 20.000000%\n",
      "At minibatch 75600, batch loss 0.914318, batch nll 0.672666, batch error rate 20.000000%\n",
      "At minibatch 75700, batch loss 0.973035, batch nll 0.731310, batch error rate 20.000000%\n",
      "At minibatch 75800, batch loss 0.856082, batch nll 0.614343, batch error rate 28.000000%\n",
      "At minibatch 75900, batch loss 1.313091, batch nll 1.071351, batch error rate 36.000000%\n",
      "At minibatch 76000, batch loss 0.707068, batch nll 0.465263, batch error rate 28.000000%\n",
      "At minibatch 76100, batch loss 1.205313, batch nll 0.963424, batch error rate 28.000000%\n",
      "At minibatch 76200, batch loss 0.565731, batch nll 0.323858, batch error rate 8.000000%\n",
      "At minibatch 76300, batch loss 0.819492, batch nll 0.577610, batch error rate 16.000000%\n",
      "At minibatch 76400, batch loss 1.075157, batch nll 0.833287, batch error rate 28.000000%\n",
      "At minibatch 76500, batch loss 0.923527, batch nll 0.681663, batch error rate 20.000000%\n",
      "At minibatch 76600, batch loss 1.217044, batch nll 0.975097, batch error rate 32.000000%\n",
      "At minibatch 76700, batch loss 0.942124, batch nll 0.700299, batch error rate 32.000000%\n",
      "At minibatch 76800, batch loss 0.707145, batch nll 0.465373, batch error rate 8.000000%\n",
      "After epoch 48: valid_err_rate: 22.210000% currently going to do 71 epochs\n",
      "After epoch 48: averaged train_err_rate: 23.805000% averaged train nll: 0.690569 averaged train loss: 0.932346\n",
      "At minibatch 76900, batch loss 0.835023, batch nll 0.593230, batch error rate 12.000000%\n",
      "At minibatch 77000, batch loss 1.036627, batch nll 0.794815, batch error rate 28.000000%\n",
      "At minibatch 77100, batch loss 0.741506, batch nll 0.499689, batch error rate 16.000000%\n",
      "At minibatch 77200, batch loss 1.061204, batch nll 0.819319, batch error rate 24.000000%\n",
      "At minibatch 77300, batch loss 0.980024, batch nll 0.738090, batch error rate 32.000000%\n",
      "At minibatch 77400, batch loss 1.048747, batch nll 0.806852, batch error rate 28.000000%\n",
      "At minibatch 77500, batch loss 0.804592, batch nll 0.562651, batch error rate 20.000000%\n",
      "At minibatch 77600, batch loss 0.898140, batch nll 0.656136, batch error rate 16.000000%\n",
      "At minibatch 77700, batch loss 0.687110, batch nll 0.445131, batch error rate 16.000000%\n",
      "At minibatch 77800, batch loss 1.203966, batch nll 0.961992, batch error rate 32.000000%\n",
      "At minibatch 77900, batch loss 1.154189, batch nll 0.912236, batch error rate 36.000000%\n",
      "At minibatch 78000, batch loss 1.018671, batch nll 0.776610, batch error rate 36.000000%\n",
      "At minibatch 78100, batch loss 0.913607, batch nll 0.671636, batch error rate 32.000000%\n",
      "At minibatch 78200, batch loss 1.026786, batch nll 0.784812, batch error rate 28.000000%\n",
      "At minibatch 78300, batch loss 0.951357, batch nll 0.709402, batch error rate 24.000000%\n",
      "At minibatch 78400, batch loss 0.955880, batch nll 0.713888, batch error rate 36.000000%\n",
      "After epoch 49: valid_err_rate: 21.160000% currently going to do 74 epochs\n",
      "After epoch 49: averaged train_err_rate: 23.670000% averaged train nll: 0.684179 averaged train loss: 0.926107\n",
      "At minibatch 78500, batch loss 1.053243, batch nll 0.811306, batch error rate 24.000000%\n",
      "At minibatch 78600, batch loss 0.732953, batch nll 0.490976, batch error rate 20.000000%\n",
      "At minibatch 78700, batch loss 0.698529, batch nll 0.456432, batch error rate 16.000000%\n",
      "At minibatch 78800, batch loss 0.891397, batch nll 0.649381, batch error rate 12.000000%\n",
      "At minibatch 78900, batch loss 0.874043, batch nll 0.631951, batch error rate 28.000000%\n",
      "At minibatch 79000, batch loss 0.726152, batch nll 0.483978, batch error rate 16.000000%\n",
      "At minibatch 79100, batch loss 0.894826, batch nll 0.652530, batch error rate 24.000000%\n",
      "At minibatch 79200, batch loss 0.852262, batch nll 0.609918, batch error rate 24.000000%\n",
      "At minibatch 79300, batch loss 0.818150, batch nll 0.575856, batch error rate 12.000000%\n",
      "At minibatch 79400, batch loss 0.903329, batch nll 0.661055, batch error rate 20.000000%\n",
      "At minibatch 79500, batch loss 0.917858, batch nll 0.675532, batch error rate 24.000000%\n",
      "At minibatch 79600, batch loss 0.885024, batch nll 0.642721, batch error rate 32.000000%\n",
      "At minibatch 79700, batch loss 0.842327, batch nll 0.600002, batch error rate 20.000000%\n",
      "At minibatch 79800, batch loss 0.850324, batch nll 0.608065, batch error rate 24.000000%\n",
      "At minibatch 79900, batch loss 0.829165, batch nll 0.586908, batch error rate 20.000000%\n",
      "At minibatch 80000, batch loss 1.386947, batch nll 1.144727, batch error rate 44.000000%\n",
      "After epoch 50: valid_err_rate: 21.450000% currently going to do 74 epochs\n",
      "After epoch 50: averaged train_err_rate: 23.807500% averaged train nll: 0.679603 averaged train loss: 0.921794\n",
      "At minibatch 80100, batch loss 0.818351, batch nll 0.576131, batch error rate 16.000000%\n",
      "At minibatch 80200, batch loss 0.812785, batch nll 0.570445, batch error rate 16.000000%\n",
      "At minibatch 80300, batch loss 0.799258, batch nll 0.556886, batch error rate 16.000000%\n",
      "At minibatch 80400, batch loss 1.383437, batch nll 1.141089, batch error rate 36.000000%\n",
      "At minibatch 80500, batch loss 1.005266, batch nll 0.762866, batch error rate 28.000000%\n",
      "At minibatch 80600, batch loss 0.736963, batch nll 0.494555, batch error rate 16.000000%\n",
      "At minibatch 80700, batch loss 1.103500, batch nll 0.861088, batch error rate 32.000000%\n",
      "At minibatch 80800, batch loss 1.045109, batch nll 0.802671, batch error rate 40.000000%\n",
      "At minibatch 80900, batch loss 1.093882, batch nll 0.851510, batch error rate 32.000000%\n",
      "At minibatch 81000, batch loss 0.812804, batch nll 0.570368, batch error rate 16.000000%\n",
      "At minibatch 81100, batch loss 1.110774, batch nll 0.868320, batch error rate 32.000000%\n",
      "At minibatch 81200, batch loss 0.912329, batch nll 0.669896, batch error rate 20.000000%\n",
      "At minibatch 81300, batch loss 0.819046, batch nll 0.576638, batch error rate 20.000000%\n",
      "At minibatch 81400, batch loss 0.665097, batch nll 0.422723, batch error rate 16.000000%\n",
      "At minibatch 81500, batch loss 1.329612, batch nll 1.087244, batch error rate 36.000000%\n",
      "At minibatch 81600, batch loss 0.872487, batch nll 0.630068, batch error rate 16.000000%\n",
      "After epoch 51: valid_err_rate: 21.510000% currently going to do 74 epochs\n",
      "After epoch 51: averaged train_err_rate: 23.660000% averaged train nll: 0.680424 averaged train loss: 0.922810\n",
      "At minibatch 81700, batch loss 0.835033, batch nll 0.592627, batch error rate 20.000000%\n",
      "At minibatch 81800, batch loss 1.318835, batch nll 1.076329, batch error rate 44.000000%\n",
      "At minibatch 81900, batch loss 0.629101, batch nll 0.386587, batch error rate 8.000000%\n",
      "At minibatch 82000, batch loss 1.043609, batch nll 0.801072, batch error rate 36.000000%\n",
      "At minibatch 82100, batch loss 1.112464, batch nll 0.869979, batch error rate 40.000000%\n",
      "At minibatch 82200, batch loss 1.145297, batch nll 0.902829, batch error rate 28.000000%\n",
      "At minibatch 82300, batch loss 0.634237, batch nll 0.391661, batch error rate 12.000000%\n",
      "At minibatch 82400, batch loss 0.927876, batch nll 0.685274, batch error rate 24.000000%\n",
      "At minibatch 82500, batch loss 0.765066, batch nll 0.522488, batch error rate 20.000000%\n",
      "At minibatch 82600, batch loss 0.588918, batch nll 0.346450, batch error rate 8.000000%\n",
      "At minibatch 82700, batch loss 1.034017, batch nll 0.791519, batch error rate 40.000000%\n",
      "At minibatch 82800, batch loss 0.793607, batch nll 0.551082, batch error rate 16.000000%\n",
      "At minibatch 82900, batch loss 0.714726, batch nll 0.472254, batch error rate 12.000000%\n",
      "At minibatch 83000, batch loss 1.089201, batch nll 0.846631, batch error rate 20.000000%\n",
      "At minibatch 83100, batch loss 0.825213, batch nll 0.582636, batch error rate 12.000000%\n",
      "At minibatch 83200, batch loss 1.055707, batch nll 0.813116, batch error rate 36.000000%\n",
      "After epoch 52: valid_err_rate: 21.160000% currently going to do 74 epochs\n",
      "After epoch 52: averaged train_err_rate: 23.557500% averaged train nll: 0.677338 averaged train loss: 0.919856\n",
      "At minibatch 83300, batch loss 1.081197, batch nll 0.838524, batch error rate 32.000000%\n",
      "At minibatch 83400, batch loss 0.626621, batch nll 0.383940, batch error rate 16.000000%\n",
      "At minibatch 83500, batch loss 0.628114, batch nll 0.385412, batch error rate 16.000000%\n",
      "At minibatch 83600, batch loss 1.196914, batch nll 0.954263, batch error rate 36.000000%\n",
      "At minibatch 83700, batch loss 1.240811, batch nll 0.998217, batch error rate 28.000000%\n",
      "At minibatch 83800, batch loss 0.546076, batch nll 0.303450, batch error rate 12.000000%\n",
      "At minibatch 83900, batch loss 0.802517, batch nll 0.559901, batch error rate 24.000000%\n",
      "At minibatch 84000, batch loss 0.692671, batch nll 0.450045, batch error rate 12.000000%\n",
      "At minibatch 84100, batch loss 1.063726, batch nll 0.821015, batch error rate 36.000000%\n",
      "At minibatch 84200, batch loss 0.806562, batch nll 0.563866, batch error rate 16.000000%\n",
      "At minibatch 84300, batch loss 0.911644, batch nll 0.668923, batch error rate 36.000000%\n",
      "At minibatch 84400, batch loss 0.885545, batch nll 0.642787, batch error rate 20.000000%\n",
      "At minibatch 84500, batch loss 1.151051, batch nll 0.908234, batch error rate 32.000000%\n",
      "At minibatch 84600, batch loss 0.713320, batch nll 0.470472, batch error rate 16.000000%\n",
      "At minibatch 84700, batch loss 0.987473, batch nll 0.744616, batch error rate 28.000000%\n",
      "At minibatch 84800, batch loss 0.593683, batch nll 0.350931, batch error rate 16.000000%\n",
      "After epoch 53: valid_err_rate: 21.630000% currently going to do 74 epochs\n",
      "After epoch 53: averaged train_err_rate: 23.460000% averaged train nll: 0.674237 averaged train loss: 0.916941\n",
      "At minibatch 84900, batch loss 0.823525, batch nll 0.580739, batch error rate 16.000000%\n",
      "At minibatch 85000, batch loss 0.895720, batch nll 0.652963, batch error rate 24.000000%\n",
      "At minibatch 85100, batch loss 0.761622, batch nll 0.518862, batch error rate 28.000000%\n",
      "At minibatch 85200, batch loss 1.265241, batch nll 1.022381, batch error rate 24.000000%\n",
      "At minibatch 85300, batch loss 0.781879, batch nll 0.539073, batch error rate 20.000000%\n",
      "At minibatch 85400, batch loss 0.901473, batch nll 0.658576, batch error rate 24.000000%\n",
      "At minibatch 85500, batch loss 1.084355, batch nll 0.841511, batch error rate 28.000000%\n",
      "At minibatch 85600, batch loss 1.043847, batch nll 0.801025, batch error rate 24.000000%\n",
      "At minibatch 85700, batch loss 1.096209, batch nll 0.853342, batch error rate 40.000000%\n",
      "At minibatch 85800, batch loss 0.744698, batch nll 0.501920, batch error rate 20.000000%\n",
      "At minibatch 85900, batch loss 0.991294, batch nll 0.748553, batch error rate 24.000000%\n",
      "At minibatch 86000, batch loss 0.594352, batch nll 0.351624, batch error rate 8.000000%\n",
      "At minibatch 86100, batch loss 1.046309, batch nll 0.803671, batch error rate 28.000000%\n",
      "At minibatch 86200, batch loss 0.997670, batch nll 0.755014, batch error rate 32.000000%\n",
      "At minibatch 86300, batch loss 0.839816, batch nll 0.597229, batch error rate 24.000000%\n",
      "At minibatch 86400, batch loss 0.878745, batch nll 0.636057, batch error rate 28.000000%\n",
      "After epoch 54: valid_err_rate: 20.360000% currently going to do 82 epochs\n",
      "After epoch 54: averaged train_err_rate: 23.402500% averaged train nll: 0.676665 averaged train loss: 0.919434\n",
      "At minibatch 86500, batch loss 0.917752, batch nll 0.674994, batch error rate 20.000000%\n",
      "At minibatch 86600, batch loss 0.789995, batch nll 0.547153, batch error rate 28.000000%\n",
      "At minibatch 86700, batch loss 0.704958, batch nll 0.462195, batch error rate 16.000000%\n",
      "At minibatch 86800, batch loss 1.016643, batch nll 0.773875, batch error rate 24.000000%\n",
      "At minibatch 86900, batch loss 1.151704, batch nll 0.908866, batch error rate 32.000000%\n",
      "At minibatch 87000, batch loss 0.710731, batch nll 0.467892, batch error rate 12.000000%\n",
      "At minibatch 87100, batch loss 0.820153, batch nll 0.577286, batch error rate 20.000000%\n",
      "At minibatch 87200, batch loss 1.014194, batch nll 0.771391, batch error rate 24.000000%\n",
      "At minibatch 87300, batch loss 0.935282, batch nll 0.692454, batch error rate 24.000000%\n",
      "At minibatch 87400, batch loss 0.853185, batch nll 0.610311, batch error rate 20.000000%\n",
      "At minibatch 87500, batch loss 0.784291, batch nll 0.541479, batch error rate 20.000000%\n",
      "At minibatch 87600, batch loss 0.801870, batch nll 0.559107, batch error rate 16.000000%\n",
      "At minibatch 87700, batch loss 0.866304, batch nll 0.623518, batch error rate 20.000000%\n",
      "At minibatch 87800, batch loss 0.729509, batch nll 0.486712, batch error rate 16.000000%\n",
      "At minibatch 87900, batch loss 0.913316, batch nll 0.670535, batch error rate 28.000000%\n",
      "At minibatch 88000, batch loss 1.005128, batch nll 0.762308, batch error rate 32.000000%\n",
      "After epoch 55: valid_err_rate: 21.030000% currently going to do 82 epochs\n",
      "After epoch 55: averaged train_err_rate: 23.465000% averaged train nll: 0.673317 averaged train loss: 0.916123\n",
      "At minibatch 88100, batch loss 1.085313, batch nll 0.842536, batch error rate 24.000000%\n",
      "At minibatch 88200, batch loss 0.737934, batch nll 0.495053, batch error rate 16.000000%\n",
      "At minibatch 88300, batch loss 1.177170, batch nll 0.934309, batch error rate 32.000000%\n",
      "At minibatch 88400, batch loss 0.920669, batch nll 0.677813, batch error rate 28.000000%\n",
      "At minibatch 88500, batch loss 0.899116, batch nll 0.656346, batch error rate 20.000000%\n",
      "At minibatch 88600, batch loss 1.345306, batch nll 1.102499, batch error rate 44.000000%\n",
      "At minibatch 88700, batch loss 0.601364, batch nll 0.358573, batch error rate 12.000000%\n",
      "At minibatch 88800, batch loss 0.902431, batch nll 0.659699, batch error rate 16.000000%\n",
      "At minibatch 88900, batch loss 1.023661, batch nll 0.780836, batch error rate 28.000000%\n",
      "At minibatch 89000, batch loss 0.849764, batch nll 0.606905, batch error rate 16.000000%\n",
      "At minibatch 89100, batch loss 1.140774, batch nll 0.897918, batch error rate 28.000000%\n",
      "At minibatch 89200, batch loss 0.690297, batch nll 0.447378, batch error rate 12.000000%\n",
      "At minibatch 89300, batch loss 0.923406, batch nll 0.680489, batch error rate 24.000000%\n",
      "At minibatch 89400, batch loss 0.946472, batch nll 0.703563, batch error rate 24.000000%\n",
      "At minibatch 89500, batch loss 0.693361, batch nll 0.450365, batch error rate 16.000000%\n",
      "At minibatch 89600, batch loss 1.028623, batch nll 0.785725, batch error rate 24.000000%\n",
      "After epoch 56: valid_err_rate: 21.300000% currently going to do 82 epochs\n",
      "After epoch 56: averaged train_err_rate: 23.270000% averaged train nll: 0.675452 averaged train loss: 0.918304\n",
      "At minibatch 89700, batch loss 0.959167, batch nll 0.716202, batch error rate 24.000000%\n",
      "At minibatch 89800, batch loss 0.753417, batch nll 0.510452, batch error rate 16.000000%\n",
      "At minibatch 89900, batch loss 0.977290, batch nll 0.734254, batch error rate 24.000000%\n",
      "At minibatch 90000, batch loss 0.936755, batch nll 0.693690, batch error rate 16.000000%\n",
      "At minibatch 90100, batch loss 0.841204, batch nll 0.598042, batch error rate 24.000000%\n",
      "At minibatch 90200, batch loss 0.770527, batch nll 0.527350, batch error rate 16.000000%\n",
      "At minibatch 90300, batch loss 0.699399, batch nll 0.456367, batch error rate 16.000000%\n",
      "At minibatch 90400, batch loss 0.771514, batch nll 0.528482, batch error rate 20.000000%\n",
      "At minibatch 90500, batch loss 0.929409, batch nll 0.686359, batch error rate 24.000000%\n",
      "At minibatch 90600, batch loss 1.399842, batch nll 1.156743, batch error rate 40.000000%\n",
      "At minibatch 90700, batch loss 1.013640, batch nll 0.770477, batch error rate 36.000000%\n",
      "At minibatch 90800, batch loss 1.012009, batch nll 0.768943, batch error rate 24.000000%\n",
      "At minibatch 90900, batch loss 1.062326, batch nll 0.819291, batch error rate 28.000000%\n",
      "At minibatch 91000, batch loss 0.766793, batch nll 0.523675, batch error rate 16.000000%\n",
      "At minibatch 91100, batch loss 1.139116, batch nll 0.895971, batch error rate 32.000000%\n",
      "At minibatch 91200, batch loss 0.820508, batch nll 0.577354, batch error rate 24.000000%\n",
      "After epoch 57: valid_err_rate: 21.810000% currently going to do 82 epochs\n",
      "After epoch 57: averaged train_err_rate: 23.017500% averaged train nll: 0.670145 averaged train loss: 0.913220\n",
      "At minibatch 91300, batch loss 0.694246, batch nll 0.451066, batch error rate 12.000000%\n",
      "At minibatch 91400, batch loss 1.208982, batch nll 0.965785, batch error rate 28.000000%\n",
      "At minibatch 91500, batch loss 0.680319, batch nll 0.437110, batch error rate 16.000000%\n",
      "At minibatch 91600, batch loss 0.834426, batch nll 0.591182, batch error rate 20.000000%\n",
      "At minibatch 91700, batch loss 1.405787, batch nll 1.162596, batch error rate 24.000000%\n",
      "At minibatch 91800, batch loss 1.481647, batch nll 1.238429, batch error rate 44.000000%\n",
      "At minibatch 91900, batch loss 0.786613, batch nll 0.543461, batch error rate 16.000000%\n",
      "At minibatch 92000, batch loss 1.269077, batch nll 1.025827, batch error rate 40.000000%\n",
      "At minibatch 92100, batch loss 1.182388, batch nll 0.939183, batch error rate 32.000000%\n",
      "At minibatch 92200, batch loss 1.000149, batch nll 0.756953, batch error rate 16.000000%\n",
      "At minibatch 92300, batch loss 1.055805, batch nll 0.812602, batch error rate 32.000000%\n",
      "At minibatch 92400, batch loss 1.059537, batch nll 0.816311, batch error rate 24.000000%\n",
      "At minibatch 92500, batch loss 1.020301, batch nll 0.777056, batch error rate 20.000000%\n",
      "At minibatch 92600, batch loss 0.842195, batch nll 0.599013, batch error rate 20.000000%\n",
      "At minibatch 92700, batch loss 1.161843, batch nll 0.918651, batch error rate 36.000000%\n",
      "At minibatch 92800, batch loss 0.671323, batch nll 0.428118, batch error rate 16.000000%\n",
      "After epoch 58: valid_err_rate: 21.080000% currently going to do 82 epochs\n",
      "After epoch 58: averaged train_err_rate: 23.067500% averaged train nll: 0.671983 averaged train loss: 0.915183\n",
      "At minibatch 92900, batch loss 0.734919, batch nll 0.491633, batch error rate 20.000000%\n",
      "At minibatch 93000, batch loss 0.900065, batch nll 0.656675, batch error rate 28.000000%\n",
      "At minibatch 93100, batch loss 0.992392, batch nll 0.748940, batch error rate 28.000000%\n",
      "At minibatch 93200, batch loss 0.980394, batch nll 0.736836, batch error rate 32.000000%\n",
      "At minibatch 93300, batch loss 0.858748, batch nll 0.615192, batch error rate 24.000000%\n",
      "At minibatch 93400, batch loss 0.789496, batch nll 0.546025, batch error rate 20.000000%\n",
      "At minibatch 93500, batch loss 1.285238, batch nll 1.041703, batch error rate 28.000000%\n",
      "At minibatch 93600, batch loss 1.014284, batch nll 0.770766, batch error rate 20.000000%\n",
      "At minibatch 93700, batch loss 1.186542, batch nll 0.943032, batch error rate 28.000000%\n",
      "At minibatch 93800, batch loss 0.932505, batch nll 0.688969, batch error rate 24.000000%\n",
      "At minibatch 93900, batch loss 1.028154, batch nll 0.784704, batch error rate 32.000000%\n",
      "At minibatch 94000, batch loss 1.027286, batch nll 0.783813, batch error rate 20.000000%\n",
      "At minibatch 94100, batch loss 0.849684, batch nll 0.606179, batch error rate 24.000000%\n",
      "At minibatch 94200, batch loss 0.650944, batch nll 0.407447, batch error rate 16.000000%\n",
      "At minibatch 94300, batch loss 1.313489, batch nll 1.069989, batch error rate 36.000000%\n",
      "At minibatch 94400, batch loss 1.025486, batch nll 0.781912, batch error rate 40.000000%\n",
      "After epoch 59: valid_err_rate: 20.940000% currently going to do 82 epochs\n",
      "After epoch 59: averaged train_err_rate: 23.092500% averaged train nll: 0.664496 averaged train loss: 0.907971\n",
      "At minibatch 94500, batch loss 0.648595, batch nll 0.404963, batch error rate 20.000000%\n",
      "At minibatch 94600, batch loss 0.637531, batch nll 0.393868, batch error rate 8.000000%\n",
      "At minibatch 94700, batch loss 1.020408, batch nll 0.776704, batch error rate 28.000000%\n",
      "At minibatch 94800, batch loss 0.745770, batch nll 0.502080, batch error rate 12.000000%\n",
      "At minibatch 94900, batch loss 0.869337, batch nll 0.625564, batch error rate 20.000000%\n",
      "At minibatch 95000, batch loss 0.862564, batch nll 0.618762, batch error rate 16.000000%\n",
      "At minibatch 95100, batch loss 0.638827, batch nll 0.394989, batch error rate 24.000000%\n",
      "At minibatch 95200, batch loss 1.029989, batch nll 0.786097, batch error rate 28.000000%\n",
      "At minibatch 95300, batch loss 0.929437, batch nll 0.685576, batch error rate 24.000000%\n",
      "At minibatch 95400, batch loss 0.853833, batch nll 0.609985, batch error rate 20.000000%\n",
      "At minibatch 95500, batch loss 0.954893, batch nll 0.711062, batch error rate 28.000000%\n",
      "At minibatch 95600, batch loss 0.949518, batch nll 0.705702, batch error rate 28.000000%\n",
      "At minibatch 95700, batch loss 1.049981, batch nll 0.806243, batch error rate 32.000000%\n",
      "At minibatch 95800, batch loss 0.925619, batch nll 0.681887, batch error rate 28.000000%\n",
      "At minibatch 95900, batch loss 1.182510, batch nll 0.938792, batch error rate 28.000000%\n",
      "At minibatch 96000, batch loss 1.083142, batch nll 0.839390, batch error rate 24.000000%\n",
      "After epoch 60: valid_err_rate: 21.080000% currently going to do 82 epochs\n",
      "After epoch 60: averaged train_err_rate: 22.950000% averaged train nll: 0.664728 averaged train loss: 0.908490\n",
      "At minibatch 96100, batch loss 0.986483, batch nll 0.742691, batch error rate 32.000000%\n",
      "At minibatch 96200, batch loss 0.746277, batch nll 0.502453, batch error rate 16.000000%\n",
      "At minibatch 96300, batch loss 0.956109, batch nll 0.712227, batch error rate 28.000000%\n",
      "At minibatch 96400, batch loss 0.680400, batch nll 0.436474, batch error rate 16.000000%\n",
      "At minibatch 96500, batch loss 0.858943, batch nll 0.615009, batch error rate 16.000000%\n",
      "At minibatch 96600, batch loss 1.197760, batch nll 0.953815, batch error rate 36.000000%\n",
      "At minibatch 96700, batch loss 0.961955, batch nll 0.717988, batch error rate 24.000000%\n",
      "At minibatch 96800, batch loss 0.881514, batch nll 0.637534, batch error rate 16.000000%\n",
      "At minibatch 96900, batch loss 1.031099, batch nll 0.787099, batch error rate 28.000000%\n",
      "At minibatch 97000, batch loss 0.777217, batch nll 0.533266, batch error rate 16.000000%\n",
      "At minibatch 97100, batch loss 0.744122, batch nll 0.500130, batch error rate 16.000000%\n",
      "At minibatch 97200, batch loss 0.675436, batch nll 0.431394, batch error rate 12.000000%\n",
      "At minibatch 97300, batch loss 1.012542, batch nll 0.768506, batch error rate 40.000000%\n",
      "At minibatch 97400, batch loss 0.776656, batch nll 0.532611, batch error rate 16.000000%\n",
      "At minibatch 97500, batch loss 0.845998, batch nll 0.601905, batch error rate 20.000000%\n",
      "At minibatch 97600, batch loss 1.057587, batch nll 0.813471, batch error rate 28.000000%\n",
      "After epoch 61: valid_err_rate: 20.810000% currently going to do 82 epochs\n",
      "After epoch 61: averaged train_err_rate: 22.822500% averaged train nll: 0.665769 averaged train loss: 0.909721\n",
      "At minibatch 97700, batch loss 0.920139, batch nll 0.676016, batch error rate 24.000000%\n",
      "At minibatch 97800, batch loss 1.057384, batch nll 0.813244, batch error rate 36.000000%\n",
      "At minibatch 97900, batch loss 0.829294, batch nll 0.585161, batch error rate 20.000000%\n",
      "At minibatch 98000, batch loss 0.826997, batch nll 0.582864, batch error rate 24.000000%\n",
      "At minibatch 98100, batch loss 0.896127, batch nll 0.651970, batch error rate 20.000000%\n",
      "At minibatch 98200, batch loss 0.772829, batch nll 0.528686, batch error rate 16.000000%\n",
      "At minibatch 98300, batch loss 1.122076, batch nll 0.877890, batch error rate 32.000000%\n",
      "At minibatch 98400, batch loss 0.823283, batch nll 0.579089, batch error rate 24.000000%\n",
      "At minibatch 98500, batch loss 1.133536, batch nll 0.889327, batch error rate 32.000000%\n",
      "At minibatch 98600, batch loss 0.709782, batch nll 0.465554, batch error rate 12.000000%\n",
      "At minibatch 98700, batch loss 1.017836, batch nll 0.773567, batch error rate 28.000000%\n",
      "At minibatch 98800, batch loss 1.014727, batch nll 0.770467, batch error rate 28.000000%\n",
      "At minibatch 98900, batch loss 1.175140, batch nll 0.930906, batch error rate 36.000000%\n",
      "At minibatch 99000, batch loss 1.012276, batch nll 0.768043, batch error rate 36.000000%\n",
      "At minibatch 99100, batch loss 1.083127, batch nll 0.838794, batch error rate 36.000000%\n",
      "At minibatch 99200, batch loss 0.669361, batch nll 0.425077, batch error rate 16.000000%\n",
      "After epoch 62: valid_err_rate: 20.540000% currently going to do 82 epochs\n",
      "After epoch 62: averaged train_err_rate: 22.827500% averaged train nll: 0.663285 averaged train loss: 0.907485\n",
      "At minibatch 99300, batch loss 0.912802, batch nll 0.668465, batch error rate 24.000000%\n",
      "At minibatch 99400, batch loss 0.975648, batch nll 0.731228, batch error rate 24.000000%\n",
      "At minibatch 99500, batch loss 0.938731, batch nll 0.694335, batch error rate 20.000000%\n",
      "At minibatch 99600, batch loss 0.648013, batch nll 0.403606, batch error rate 8.000000%\n",
      "At minibatch 99700, batch loss 1.003458, batch nll 0.758990, batch error rate 36.000000%\n",
      "At minibatch 99800, batch loss 0.912326, batch nll 0.667894, batch error rate 20.000000%\n",
      "At minibatch 99900, batch loss 1.039613, batch nll 0.795200, batch error rate 16.000000%\n",
      "At minibatch 100000, batch loss 1.010606, batch nll 0.766139, batch error rate 28.000000%\n",
      "At minibatch 100100, batch loss 0.655282, batch nll 0.410812, batch error rate 12.000000%\n",
      "At minibatch 100200, batch loss 0.773777, batch nll 0.529287, batch error rate 20.000000%\n",
      "At minibatch 100300, batch loss 1.032985, batch nll 0.788409, batch error rate 16.000000%\n",
      "At minibatch 100400, batch loss 0.948712, batch nll 0.704165, batch error rate 24.000000%\n",
      "At minibatch 100500, batch loss 0.882676, batch nll 0.638129, batch error rate 28.000000%\n",
      "At minibatch 100600, batch loss 0.967143, batch nll 0.722623, batch error rate 24.000000%\n",
      "At minibatch 100700, batch loss 0.780912, batch nll 0.536354, batch error rate 20.000000%\n",
      "At minibatch 100800, batch loss 0.915275, batch nll 0.670754, batch error rate 12.000000%\n",
      "After epoch 63: valid_err_rate: 21.660000% currently going to do 82 epochs\n",
      "After epoch 63: averaged train_err_rate: 22.927500% averaged train nll: 0.655619 averaged train loss: 0.900075\n",
      "At minibatch 100900, batch loss 0.661390, batch nll 0.416778, batch error rate 12.000000%\n",
      "At minibatch 101000, batch loss 0.782296, batch nll 0.537682, batch error rate 16.000000%\n",
      "At minibatch 101100, batch loss 1.116911, batch nll 0.872218, batch error rate 32.000000%\n",
      "At minibatch 101200, batch loss 0.731100, batch nll 0.486392, batch error rate 16.000000%\n",
      "At minibatch 101300, batch loss 0.895051, batch nll 0.650279, batch error rate 28.000000%\n",
      "At minibatch 101400, batch loss 0.928337, batch nll 0.683518, batch error rate 24.000000%\n",
      "At minibatch 101500, batch loss 0.883424, batch nll 0.638572, batch error rate 20.000000%\n",
      "At minibatch 101600, batch loss 0.765830, batch nll 0.520972, batch error rate 24.000000%\n",
      "At minibatch 101700, batch loss 0.860041, batch nll 0.615201, batch error rate 24.000000%\n",
      "At minibatch 101800, batch loss 0.797519, batch nll 0.552668, batch error rate 24.000000%\n",
      "At minibatch 101900, batch loss 1.276427, batch nll 1.031528, batch error rate 40.000000%\n",
      "At minibatch 102000, batch loss 1.028456, batch nll 0.783570, batch error rate 20.000000%\n",
      "At minibatch 102100, batch loss 0.716561, batch nll 0.471716, batch error rate 16.000000%\n",
      "At minibatch 102200, batch loss 0.962118, batch nll 0.717262, batch error rate 32.000000%\n",
      "At minibatch 102300, batch loss 0.951572, batch nll 0.706747, batch error rate 32.000000%\n",
      "At minibatch 102400, batch loss 0.730799, batch nll 0.485996, batch error rate 20.000000%\n",
      "After epoch 64: valid_err_rate: 20.740000% currently going to do 82 epochs\n",
      "After epoch 64: averaged train_err_rate: 22.642500% averaged train nll: 0.659868 averaged train loss: 0.904650\n",
      "At minibatch 102500, batch loss 1.038398, batch nll 0.793494, batch error rate 40.000000%\n",
      "At minibatch 102600, batch loss 0.810546, batch nll 0.565585, batch error rate 16.000000%\n",
      "At minibatch 102700, batch loss 1.151926, batch nll 0.906907, batch error rate 28.000000%\n",
      "At minibatch 102800, batch loss 1.093142, batch nll 0.848132, batch error rate 24.000000%\n",
      "At minibatch 102900, batch loss 0.971457, batch nll 0.726489, batch error rate 28.000000%\n",
      "At minibatch 103000, batch loss 0.963723, batch nll 0.718773, batch error rate 20.000000%\n",
      "At minibatch 103100, batch loss 0.945764, batch nll 0.700854, batch error rate 16.000000%\n",
      "At minibatch 103200, batch loss 0.583990, batch nll 0.339087, batch error rate 16.000000%\n",
      "At minibatch 103300, batch loss 0.701984, batch nll 0.457083, batch error rate 20.000000%\n",
      "At minibatch 103400, batch loss 0.915462, batch nll 0.670503, batch error rate 20.000000%\n",
      "At minibatch 103500, batch loss 0.904263, batch nll 0.659318, batch error rate 28.000000%\n",
      "At minibatch 103600, batch loss 0.885768, batch nll 0.640762, batch error rate 16.000000%\n",
      "At minibatch 103700, batch loss 1.022969, batch nll 0.777942, batch error rate 20.000000%\n",
      "At minibatch 103800, batch loss 0.926036, batch nll 0.680965, batch error rate 16.000000%\n",
      "At minibatch 103900, batch loss 0.589300, batch nll 0.344234, batch error rate 12.000000%\n",
      "At minibatch 104000, batch loss 0.937429, batch nll 0.692380, batch error rate 28.000000%\n",
      "After epoch 65: valid_err_rate: 20.640000% currently going to do 82 epochs\n",
      "After epoch 65: averaged train_err_rate: 22.590000% averaged train nll: 0.651941 averaged train loss: 0.896911\n",
      "At minibatch 104100, batch loss 1.137076, batch nll 0.891988, batch error rate 36.000000%\n",
      "At minibatch 104200, batch loss 1.261426, batch nll 1.016263, batch error rate 36.000000%\n",
      "At minibatch 104300, batch loss 0.740175, batch nll 0.494995, batch error rate 12.000000%\n",
      "At minibatch 104400, batch loss 1.085718, batch nll 0.840555, batch error rate 28.000000%\n",
      "At minibatch 104500, batch loss 0.907634, batch nll 0.662463, batch error rate 32.000000%\n",
      "At minibatch 104600, batch loss 1.199633, batch nll 0.954448, batch error rate 40.000000%\n",
      "At minibatch 104700, batch loss 0.927857, batch nll 0.682682, batch error rate 20.000000%\n",
      "At minibatch 104800, batch loss 1.088819, batch nll 0.843624, batch error rate 28.000000%\n",
      "At minibatch 104900, batch loss 0.875545, batch nll 0.630331, batch error rate 20.000000%\n",
      "At minibatch 105000, batch loss 0.517844, batch nll 0.272614, batch error rate 0.000000%\n",
      "At minibatch 105100, batch loss 0.911865, batch nll 0.666592, batch error rate 24.000000%\n",
      "At minibatch 105200, batch loss 0.983873, batch nll 0.738569, batch error rate 28.000000%\n",
      "At minibatch 105300, batch loss 0.854508, batch nll 0.609254, batch error rate 24.000000%\n",
      "At minibatch 105400, batch loss 1.014580, batch nll 0.769348, batch error rate 32.000000%\n",
      "At minibatch 105500, batch loss 1.080764, batch nll 0.835539, batch error rate 32.000000%\n",
      "At minibatch 105600, batch loss 0.715307, batch nll 0.470098, batch error rate 20.000000%\n",
      "After epoch 66: valid_err_rate: 21.170000% currently going to do 82 epochs\n",
      "After epoch 66: averaged train_err_rate: 22.610000% averaged train nll: 0.656363 averaged train loss: 0.901565\n",
      "At minibatch 105700, batch loss 0.987359, batch nll 0.742194, batch error rate 36.000000%\n",
      "At minibatch 105800, batch loss 1.284785, batch nll 1.039566, batch error rate 44.000000%\n",
      "At minibatch 105900, batch loss 0.922038, batch nll 0.676774, batch error rate 16.000000%\n",
      "At minibatch 106000, batch loss 0.704942, batch nll 0.459649, batch error rate 12.000000%\n",
      "At minibatch 106100, batch loss 1.221428, batch nll 0.976060, batch error rate 32.000000%\n",
      "At minibatch 106200, batch loss 0.886002, batch nll 0.640639, batch error rate 24.000000%\n",
      "At minibatch 106300, batch loss 0.790591, batch nll 0.545250, batch error rate 20.000000%\n",
      "At minibatch 106400, batch loss 0.835802, batch nll 0.590434, batch error rate 16.000000%\n",
      "At minibatch 106500, batch loss 1.039477, batch nll 0.794175, batch error rate 28.000000%\n",
      "At minibatch 106600, batch loss 1.163207, batch nll 0.917834, batch error rate 32.000000%\n",
      "At minibatch 106700, batch loss 0.912308, batch nll 0.666947, batch error rate 20.000000%\n",
      "At minibatch 106800, batch loss 0.952904, batch nll 0.707515, batch error rate 24.000000%\n",
      "At minibatch 106900, batch loss 0.776263, batch nll 0.530870, batch error rate 16.000000%\n",
      "At minibatch 107000, batch loss 0.988001, batch nll 0.742585, batch error rate 28.000000%\n",
      "At minibatch 107100, batch loss 0.967150, batch nll 0.721685, batch error rate 20.000000%\n",
      "At minibatch 107200, batch loss 1.117961, batch nll 0.872489, batch error rate 24.000000%\n",
      "After epoch 67: valid_err_rate: 20.580000% currently going to do 82 epochs\n",
      "After epoch 67: averaged train_err_rate: 22.535000% averaged train nll: 0.655832 averaged train loss: 0.901172\n",
      "At minibatch 107300, batch loss 0.846580, batch nll 0.601124, batch error rate 20.000000%\n",
      "At minibatch 107400, batch loss 0.875630, batch nll 0.630169, batch error rate 24.000000%\n",
      "At minibatch 107500, batch loss 0.967702, batch nll 0.722267, batch error rate 28.000000%\n",
      "At minibatch 107600, batch loss 1.230864, batch nll 0.985384, batch error rate 32.000000%\n",
      "At minibatch 107700, batch loss 1.097334, batch nll 0.851782, batch error rate 28.000000%\n",
      "At minibatch 107800, batch loss 0.974175, batch nll 0.728593, batch error rate 24.000000%\n",
      "At minibatch 107900, batch loss 0.968817, batch nll 0.723290, batch error rate 36.000000%\n",
      "At minibatch 108000, batch loss 1.066299, batch nll 0.820785, batch error rate 36.000000%\n",
      "At minibatch 108100, batch loss 1.265715, batch nll 1.020206, batch error rate 32.000000%\n",
      "At minibatch 108200, batch loss 0.753245, batch nll 0.507722, batch error rate 24.000000%\n",
      "At minibatch 108300, batch loss 1.089506, batch nll 0.843914, batch error rate 24.000000%\n",
      "At minibatch 108400, batch loss 1.051103, batch nll 0.805491, batch error rate 16.000000%\n",
      "At minibatch 108500, batch loss 0.835246, batch nll 0.589598, batch error rate 12.000000%\n",
      "At minibatch 108600, batch loss 0.954993, batch nll 0.709378, batch error rate 36.000000%\n",
      "At minibatch 108700, batch loss 1.030997, batch nll 0.785315, batch error rate 24.000000%\n",
      "At minibatch 108800, batch loss 0.751762, batch nll 0.506107, batch error rate 16.000000%\n",
      "After epoch 68: valid_err_rate: 20.770000% currently going to do 82 epochs\n",
      "After epoch 68: averaged train_err_rate: 22.602500% averaged train nll: 0.652668 averaged train loss: 0.898218\n",
      "At minibatch 108900, batch loss 0.936656, batch nll 0.691013, batch error rate 36.000000%\n",
      "At minibatch 109000, batch loss 1.043912, batch nll 0.798241, batch error rate 40.000000%\n",
      "At minibatch 109100, batch loss 0.970300, batch nll 0.724607, batch error rate 28.000000%\n",
      "At minibatch 109200, batch loss 1.162120, batch nll 0.916482, batch error rate 32.000000%\n",
      "At minibatch 109300, batch loss 0.883434, batch nll 0.637719, batch error rate 24.000000%\n",
      "At minibatch 109400, batch loss 0.785825, batch nll 0.540114, batch error rate 24.000000%\n",
      "At minibatch 109500, batch loss 1.167182, batch nll 0.921468, batch error rate 24.000000%\n",
      "At minibatch 109600, batch loss 1.097690, batch nll 0.851980, batch error rate 32.000000%\n",
      "At minibatch 109700, batch loss 0.873684, batch nll 0.627893, batch error rate 36.000000%\n",
      "At minibatch 109800, batch loss 0.717178, batch nll 0.471379, batch error rate 16.000000%\n",
      "At minibatch 109900, batch loss 0.865562, batch nll 0.619691, batch error rate 20.000000%\n",
      "At minibatch 110000, batch loss 0.806983, batch nll 0.561033, batch error rate 28.000000%\n",
      "At minibatch 110100, batch loss 1.000093, batch nll 0.754106, batch error rate 32.000000%\n",
      "At minibatch 110200, batch loss 0.932307, batch nll 0.686342, batch error rate 24.000000%\n",
      "At minibatch 110300, batch loss 0.954052, batch nll 0.708077, batch error rate 16.000000%\n",
      "At minibatch 110400, batch loss 0.883281, batch nll 0.637266, batch error rate 8.000000%\n",
      "After epoch 69: valid_err_rate: 20.220000% currently going to do 104 epochs\n",
      "After epoch 69: averaged train_err_rate: 22.465000% averaged train nll: 0.649866 averaged train loss: 0.895657\n",
      "At minibatch 110500, batch loss 0.978930, batch nll 0.732849, batch error rate 32.000000%\n",
      "At minibatch 110600, batch loss 0.868760, batch nll 0.622666, batch error rate 20.000000%\n",
      "At minibatch 110700, batch loss 1.067345, batch nll 0.821277, batch error rate 36.000000%\n",
      "At minibatch 110800, batch loss 0.720153, batch nll 0.474140, batch error rate 12.000000%\n",
      "At minibatch 110900, batch loss 1.070938, batch nll 0.824987, batch error rate 28.000000%\n",
      "At minibatch 111000, batch loss 0.812004, batch nll 0.565986, batch error rate 12.000000%\n",
      "At minibatch 111100, batch loss 0.851568, batch nll 0.605570, batch error rate 16.000000%\n",
      "At minibatch 111200, batch loss 0.839611, batch nll 0.593568, batch error rate 16.000000%\n",
      "At minibatch 111300, batch loss 0.566295, batch nll 0.320265, batch error rate 8.000000%\n",
      "At minibatch 111400, batch loss 1.037119, batch nll 0.791056, batch error rate 24.000000%\n",
      "At minibatch 111500, batch loss 0.653960, batch nll 0.407885, batch error rate 12.000000%\n",
      "At minibatch 111600, batch loss 0.877923, batch nll 0.631837, batch error rate 28.000000%\n",
      "At minibatch 111700, batch loss 1.164693, batch nll 0.918627, batch error rate 24.000000%\n",
      "At minibatch 111800, batch loss 0.867733, batch nll 0.621706, batch error rate 24.000000%\n",
      "At minibatch 111900, batch loss 0.742740, batch nll 0.496715, batch error rate 12.000000%\n",
      "At minibatch 112000, batch loss 0.707981, batch nll 0.461975, batch error rate 16.000000%\n",
      "After epoch 70: valid_err_rate: 19.990000% currently going to do 106 epochs\n",
      "After epoch 70: averaged train_err_rate: 22.550000% averaged train nll: 0.649242 averaged train loss: 0.895282\n",
      "At minibatch 112100, batch loss 0.908469, batch nll 0.662422, batch error rate 20.000000%\n",
      "At minibatch 112200, batch loss 1.151303, batch nll 0.905173, batch error rate 36.000000%\n",
      "At minibatch 112300, batch loss 0.685360, batch nll 0.439220, batch error rate 12.000000%\n",
      "At minibatch 112400, batch loss 0.807874, batch nll 0.561721, batch error rate 20.000000%\n",
      "At minibatch 112500, batch loss 0.720241, batch nll 0.474103, batch error rate 12.000000%\n",
      "At minibatch 112600, batch loss 0.710566, batch nll 0.464445, batch error rate 8.000000%\n",
      "At minibatch 112700, batch loss 0.776757, batch nll 0.530623, batch error rate 12.000000%\n",
      "At minibatch 112800, batch loss 1.161688, batch nll 0.915494, batch error rate 24.000000%\n",
      "At minibatch 112900, batch loss 0.752663, batch nll 0.506392, batch error rate 12.000000%\n",
      "At minibatch 113000, batch loss 0.689198, batch nll 0.442938, batch error rate 12.000000%\n",
      "At minibatch 113100, batch loss 0.746978, batch nll 0.500753, batch error rate 20.000000%\n",
      "At minibatch 113200, batch loss 1.100025, batch nll 0.853850, batch error rate 32.000000%\n",
      "At minibatch 113300, batch loss 0.736924, batch nll 0.490783, batch error rate 16.000000%\n",
      "At minibatch 113400, batch loss 1.069711, batch nll 0.823514, batch error rate 24.000000%\n",
      "At minibatch 113500, batch loss 1.070163, batch nll 0.823941, batch error rate 36.000000%\n",
      "At minibatch 113600, batch loss 0.945759, batch nll 0.699556, batch error rate 28.000000%\n",
      "After epoch 71: valid_err_rate: 20.230000% currently going to do 106 epochs\n",
      "After epoch 71: averaged train_err_rate: 22.302500% averaged train nll: 0.650584 averaged train loss: 0.896748\n",
      "At minibatch 113700, batch loss 0.931899, batch nll 0.685657, batch error rate 20.000000%\n",
      "At minibatch 113800, batch loss 0.923065, batch nll 0.676806, batch error rate 20.000000%\n",
      "At minibatch 113900, batch loss 0.827945, batch nll 0.581720, batch error rate 20.000000%\n",
      "At minibatch 114000, batch loss 0.757168, batch nll 0.510927, batch error rate 16.000000%\n",
      "At minibatch 114100, batch loss 0.793812, batch nll 0.547531, batch error rate 20.000000%\n",
      "At minibatch 114200, batch loss 0.642260, batch nll 0.395986, batch error rate 16.000000%\n",
      "At minibatch 114300, batch loss 0.953167, batch nll 0.706847, batch error rate 24.000000%\n",
      "At minibatch 114400, batch loss 0.690825, batch nll 0.444460, batch error rate 16.000000%\n",
      "At minibatch 114500, batch loss 1.048861, batch nll 0.802568, batch error rate 32.000000%\n",
      "At minibatch 114600, batch loss 0.991855, batch nll 0.745549, batch error rate 28.000000%\n",
      "At minibatch 114700, batch loss 0.915949, batch nll 0.669599, batch error rate 28.000000%\n",
      "At minibatch 114800, batch loss 1.045227, batch nll 0.798905, batch error rate 36.000000%\n",
      "At minibatch 114900, batch loss 0.962231, batch nll 0.715913, batch error rate 28.000000%\n",
      "At minibatch 115000, batch loss 1.046792, batch nll 0.800418, batch error rate 28.000000%\n",
      "At minibatch 115100, batch loss 1.007552, batch nll 0.761169, batch error rate 16.000000%\n",
      "At minibatch 115200, batch loss 1.064472, batch nll 0.818156, batch error rate 32.000000%\n",
      "After epoch 72: valid_err_rate: 20.200000% currently going to do 106 epochs\n",
      "After epoch 72: averaged train_err_rate: 22.505000% averaged train nll: 0.647739 averaged train loss: 0.894037\n",
      "At minibatch 115300, batch loss 0.580972, batch nll 0.334641, batch error rate 8.000000%\n",
      "At minibatch 115400, batch loss 0.874121, batch nll 0.627781, batch error rate 16.000000%\n",
      "At minibatch 115500, batch loss 0.940328, batch nll 0.693977, batch error rate 24.000000%\n",
      "At minibatch 115600, batch loss 1.155887, batch nll 0.909501, batch error rate 28.000000%\n",
      "At minibatch 115700, batch loss 1.016290, batch nll 0.769849, batch error rate 28.000000%\n",
      "At minibatch 115800, batch loss 0.786478, batch nll 0.539986, batch error rate 20.000000%\n",
      "At minibatch 115900, batch loss 0.717540, batch nll 0.471070, batch error rate 20.000000%\n",
      "At minibatch 116000, batch loss 0.923935, batch nll 0.677464, batch error rate 24.000000%\n",
      "At minibatch 116100, batch loss 1.106298, batch nll 0.859822, batch error rate 24.000000%\n",
      "At minibatch 116200, batch loss 1.265672, batch nll 1.019222, batch error rate 28.000000%\n",
      "At minibatch 116300, batch loss 1.083002, batch nll 0.836589, batch error rate 24.000000%\n",
      "At minibatch 116400, batch loss 0.726775, batch nll 0.480321, batch error rate 12.000000%\n",
      "At minibatch 116500, batch loss 0.930098, batch nll 0.683607, batch error rate 24.000000%\n",
      "At minibatch 116600, batch loss 0.873620, batch nll 0.627102, batch error rate 20.000000%\n",
      "At minibatch 116700, batch loss 1.125822, batch nll 0.879311, batch error rate 28.000000%\n",
      "At minibatch 116800, batch loss 0.632380, batch nll 0.385885, batch error rate 12.000000%\n",
      "After epoch 73: valid_err_rate: 20.500000% currently going to do 106 epochs\n",
      "After epoch 73: averaged train_err_rate: 22.415000% averaged train nll: 0.646505 averaged train loss: 0.892942\n",
      "At minibatch 116900, batch loss 1.088842, batch nll 0.842265, batch error rate 28.000000%\n",
      "At minibatch 117000, batch loss 0.679816, batch nll 0.433215, batch error rate 12.000000%\n",
      "At minibatch 117100, batch loss 0.830693, batch nll 0.584110, batch error rate 20.000000%\n",
      "At minibatch 117200, batch loss 0.874762, batch nll 0.628168, batch error rate 28.000000%\n",
      "At minibatch 117300, batch loss 1.095556, batch nll 0.848997, batch error rate 24.000000%\n",
      "At minibatch 117400, batch loss 1.086771, batch nll 0.840233, batch error rate 28.000000%\n",
      "At minibatch 117500, batch loss 0.946005, batch nll 0.699510, batch error rate 24.000000%\n",
      "At minibatch 117600, batch loss 0.760385, batch nll 0.513777, batch error rate 16.000000%\n",
      "At minibatch 117700, batch loss 0.728672, batch nll 0.482071, batch error rate 20.000000%\n",
      "At minibatch 117800, batch loss 0.601608, batch nll 0.354987, batch error rate 8.000000%\n",
      "At minibatch 117900, batch loss 0.882712, batch nll 0.636096, batch error rate 32.000000%\n",
      "At minibatch 118000, batch loss 0.977400, batch nll 0.730773, batch error rate 24.000000%\n",
      "At minibatch 118100, batch loss 0.881287, batch nll 0.634653, batch error rate 20.000000%\n",
      "At minibatch 118200, batch loss 1.127183, batch nll 0.880561, batch error rate 28.000000%\n",
      "At minibatch 118300, batch loss 0.923404, batch nll 0.676786, batch error rate 36.000000%\n",
      "At minibatch 118400, batch loss 0.667510, batch nll 0.420840, batch error rate 16.000000%\n",
      "After epoch 74: valid_err_rate: 20.430000% currently going to do 106 epochs\n",
      "After epoch 74: averaged train_err_rate: 22.335000% averaged train nll: 0.645059 averaged train loss: 0.891648\n",
      "At minibatch 118500, batch loss 1.038489, batch nll 0.791844, batch error rate 36.000000%\n",
      "At minibatch 118600, batch loss 0.692356, batch nll 0.445746, batch error rate 12.000000%\n",
      "At minibatch 118700, batch loss 0.702847, batch nll 0.456188, batch error rate 8.000000%\n",
      "At minibatch 118800, batch loss 0.557540, batch nll 0.310844, batch error rate 12.000000%\n",
      "At minibatch 118900, batch loss 0.715349, batch nll 0.468647, batch error rate 16.000000%\n",
      "At minibatch 119000, batch loss 0.789871, batch nll 0.543155, batch error rate 32.000000%\n",
      "At minibatch 119100, batch loss 0.624219, batch nll 0.377492, batch error rate 8.000000%\n",
      "At minibatch 119200, batch loss 0.844606, batch nll 0.597875, batch error rate 16.000000%\n",
      "At minibatch 119300, batch loss 0.880930, batch nll 0.634172, batch error rate 24.000000%\n",
      "At minibatch 119400, batch loss 0.800252, batch nll 0.553519, batch error rate 16.000000%\n",
      "At minibatch 119500, batch loss 0.730014, batch nll 0.483238, batch error rate 8.000000%\n",
      "At minibatch 119600, batch loss 0.695434, batch nll 0.448640, batch error rate 20.000000%\n",
      "At minibatch 119700, batch loss 1.039006, batch nll 0.792231, batch error rate 28.000000%\n",
      "At minibatch 119800, batch loss 1.078399, batch nll 0.831640, batch error rate 32.000000%\n",
      "At minibatch 119900, batch loss 0.872122, batch nll 0.625327, batch error rate 20.000000%\n",
      "At minibatch 120000, batch loss 1.276163, batch nll 1.029378, batch error rate 40.000000%\n",
      "After epoch 75: valid_err_rate: 20.510000% currently going to do 106 epochs\n",
      "After epoch 75: averaged train_err_rate: 22.237500% averaged train nll: 0.645689 averaged train loss: 0.892418\n",
      "At minibatch 120100, batch loss 0.912250, batch nll 0.665427, batch error rate 24.000000%\n",
      "At minibatch 120200, batch loss 1.055408, batch nll 0.808589, batch error rate 24.000000%\n",
      "At minibatch 120300, batch loss 0.855842, batch nll 0.609005, batch error rate 24.000000%\n",
      "At minibatch 120400, batch loss 1.012463, batch nll 0.765592, batch error rate 28.000000%\n",
      "At minibatch 120500, batch loss 1.128890, batch nll 0.882071, batch error rate 40.000000%\n",
      "At minibatch 120600, batch loss 0.893975, batch nll 0.647145, batch error rate 20.000000%\n",
      "At minibatch 120700, batch loss 0.775577, batch nll 0.528719, batch error rate 28.000000%\n",
      "At minibatch 120800, batch loss 0.786477, batch nll 0.539625, batch error rate 20.000000%\n",
      "At minibatch 120900, batch loss 0.816342, batch nll 0.569440, batch error rate 12.000000%\n",
      "At minibatch 121000, batch loss 0.901745, batch nll 0.654850, batch error rate 28.000000%\n",
      "At minibatch 121100, batch loss 0.553633, batch nll 0.306775, batch error rate 16.000000%\n",
      "At minibatch 121200, batch loss 0.994722, batch nll 0.747828, batch error rate 28.000000%\n",
      "At minibatch 121300, batch loss 0.823950, batch nll 0.577024, batch error rate 16.000000%\n",
      "At minibatch 121400, batch loss 0.997905, batch nll 0.750929, batch error rate 40.000000%\n",
      "At minibatch 121500, batch loss 0.725937, batch nll 0.479028, batch error rate 16.000000%\n",
      "At minibatch 121600, batch loss 0.893035, batch nll 0.646147, batch error rate 24.000000%\n",
      "After epoch 76: valid_err_rate: 21.020000% currently going to do 106 epochs\n",
      "After epoch 76: averaged train_err_rate: 22.175000% averaged train nll: 0.644752 averaged train loss: 0.891620\n",
      "At minibatch 121700, batch loss 1.236540, batch nll 0.989614, batch error rate 28.000000%\n",
      "At minibatch 121800, batch loss 0.872815, batch nll 0.625846, batch error rate 12.000000%\n",
      "At minibatch 121900, batch loss 0.916021, batch nll 0.669019, batch error rate 20.000000%\n",
      "At minibatch 122000, batch loss 1.026167, batch nll 0.779167, batch error rate 20.000000%\n",
      "At minibatch 122100, batch loss 0.704424, batch nll 0.457442, batch error rate 16.000000%\n",
      "At minibatch 122200, batch loss 1.083226, batch nll 0.836237, batch error rate 36.000000%\n",
      "At minibatch 122300, batch loss 0.826377, batch nll 0.579347, batch error rate 36.000000%\n",
      "At minibatch 122400, batch loss 1.101732, batch nll 0.854748, batch error rate 28.000000%\n",
      "At minibatch 122500, batch loss 1.021562, batch nll 0.774528, batch error rate 20.000000%\n",
      "At minibatch 122600, batch loss 0.860139, batch nll 0.613086, batch error rate 20.000000%\n",
      "At minibatch 122700, batch loss 1.125823, batch nll 0.878805, batch error rate 28.000000%\n",
      "At minibatch 122800, batch loss 0.997285, batch nll 0.750226, batch error rate 32.000000%\n",
      "At minibatch 122900, batch loss 0.972857, batch nll 0.725784, batch error rate 28.000000%\n",
      "At minibatch 123000, batch loss 0.886825, batch nll 0.639779, batch error rate 32.000000%\n",
      "At minibatch 123100, batch loss 0.707106, batch nll 0.460028, batch error rate 12.000000%\n",
      "At minibatch 123200, batch loss 0.596682, batch nll 0.349672, batch error rate 12.000000%\n",
      "After epoch 77: valid_err_rate: 20.670000% currently going to do 106 epochs\n",
      "After epoch 77: averaged train_err_rate: 21.890000% averaged train nll: 0.640866 averaged train loss: 0.887881\n",
      "At minibatch 123300, batch loss 1.048891, batch nll 0.801839, batch error rate 36.000000%\n",
      "At minibatch 123400, batch loss 0.728086, batch nll 0.481015, batch error rate 12.000000%\n",
      "At minibatch 123500, batch loss 0.759320, batch nll 0.512220, batch error rate 16.000000%\n",
      "At minibatch 123600, batch loss 0.799455, batch nll 0.552375, batch error rate 20.000000%\n",
      "At minibatch 123700, batch loss 1.096489, batch nll 0.849354, batch error rate 32.000000%\n",
      "At minibatch 123800, batch loss 0.821759, batch nll 0.574616, batch error rate 12.000000%\n",
      "At minibatch 123900, batch loss 0.878634, batch nll 0.631488, batch error rate 24.000000%\n",
      "At minibatch 124000, batch loss 1.117935, batch nll 0.870756, batch error rate 32.000000%\n",
      "At minibatch 124100, batch loss 0.994491, batch nll 0.747295, batch error rate 32.000000%\n",
      "At minibatch 124200, batch loss 0.845794, batch nll 0.598656, batch error rate 20.000000%\n",
      "At minibatch 124300, batch loss 0.994238, batch nll 0.747095, batch error rate 24.000000%\n",
      "At minibatch 124400, batch loss 0.892723, batch nll 0.645522, batch error rate 24.000000%\n",
      "At minibatch 124500, batch loss 0.683670, batch nll 0.436456, batch error rate 16.000000%\n",
      "At minibatch 124600, batch loss 0.772609, batch nll 0.525358, batch error rate 28.000000%\n",
      "At minibatch 124700, batch loss 0.993318, batch nll 0.746082, batch error rate 28.000000%\n",
      "At minibatch 124800, batch loss 0.888078, batch nll 0.640816, batch error rate 24.000000%\n",
      "After epoch 78: valid_err_rate: 20.070000% currently going to do 106 epochs\n",
      "After epoch 78: averaged train_err_rate: 22.260000% averaged train nll: 0.643845 averaged train loss: 0.891000\n",
      "At minibatch 124900, batch loss 0.627841, batch nll 0.380548, batch error rate 12.000000%\n",
      "At minibatch 125000, batch loss 0.706061, batch nll 0.458753, batch error rate 12.000000%\n",
      "At minibatch 125100, batch loss 0.737278, batch nll 0.489934, batch error rate 16.000000%\n",
      "At minibatch 125200, batch loss 0.628203, batch nll 0.380807, batch error rate 8.000000%\n",
      "At minibatch 125300, batch loss 0.833285, batch nll 0.585916, batch error rate 20.000000%\n",
      "At minibatch 125400, batch loss 0.692085, batch nll 0.444659, batch error rate 12.000000%\n",
      "At minibatch 125500, batch loss 0.977045, batch nll 0.729620, batch error rate 28.000000%\n",
      "At minibatch 125600, batch loss 0.843807, batch nll 0.596401, batch error rate 12.000000%\n",
      "At minibatch 125700, batch loss 1.221074, batch nll 0.973690, batch error rate 28.000000%\n",
      "At minibatch 125800, batch loss 1.166532, batch nll 0.919120, batch error rate 44.000000%\n",
      "At minibatch 125900, batch loss 0.669361, batch nll 0.421978, batch error rate 20.000000%\n",
      "At minibatch 126000, batch loss 0.870596, batch nll 0.623260, batch error rate 20.000000%\n",
      "At minibatch 126100, batch loss 0.641121, batch nll 0.393780, batch error rate 8.000000%\n",
      "At minibatch 126200, batch loss 1.345661, batch nll 1.098314, batch error rate 40.000000%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-0d565a7a302c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;31m#new_Y_batch = np.tile(Y_batch, (repeats+1, 1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[0mL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwdec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_X_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlrate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mL\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/Desktop/nn_assignments/libs/Theano/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    857\u001b[0m         \u001b[0mt0_fn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'position_of_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/i258346/Desktop/nn_assignments/libs/Theano/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    876\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    877\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 878\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    879\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    880\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# training loop\n",
    "t = time.time()\n",
    "\n",
    "while e < number_of_epochs: #This loop goes over epochs\n",
    "    e += 1\n",
    "    #First train on all data from this batch\n",
    "    epoch_start_i = i\n",
    "    for X_batch, Y_batch in cifar10_train_stream.get_epoch_iterator(): \n",
    "        i += 1\n",
    "        \n",
    "        K = 5000\n",
    "        lrate = 1e-2 * K / np.maximum(K, i)\n",
    "        \n",
    "        momentum = 0.9\n",
    "        \n",
    "        repeats = 1\n",
    "        shift_range = 4\n",
    "        \n",
    "        new_X_batch = simulate_data(X_batch, repeats, shift_range)\n",
    "        new_Y_batch = np.tile(Y_batch, (repeats+1, 1))\n",
    "        \n",
    "        L, err_rate, nll, wdec = train_step(new_X_batch, new_Y_batch, lrate, momentum)        \n",
    "        \n",
    "        train_loss.append((i,L))\n",
    "        train_erros.append((i,err_rate))\n",
    "        train_nll.append((i,nll))\n",
    "        if i % 100 == 0:\n",
    "            print \"At minibatch %d, batch loss %f, batch nll %f, batch error rate %f%%\" % (i, L, nll, err_rate*100)\n",
    "        \n",
    "    # After an epoch compute validation error\n",
    "    val_error_rate = compute_error_rate(cifar10_validation_stream)\n",
    "    if val_error_rate < best_valid_error_rate:\n",
    "        number_of_epochs = np.maximum(number_of_epochs, e*patience_expansion + 1)\n",
    "        best_valid_error_rate = val_error_rate\n",
    "        best_params = snapshot_parameters()\n",
    "        best_params_epoch = e\n",
    "    validation_errors.append((i,val_error_rate))\n",
    "    print \"After epoch %d: valid_err_rate: %f%% currently going to do %d epochs\" %(\n",
    "        e, val_error_rate*100, number_of_epochs)\n",
    "    print \"After epoch %d: averaged train_err_rate: %f%% averaged train nll: %f averaged train loss: %f\" %(\n",
    "        e, np.mean(np.asarray(train_erros)[epoch_start_i:,1])*100, \n",
    "        np.mean(np.asarray(train_nll)[epoch_start_i:,1]),\n",
    "        np.mean(np.asarray(train_loss)[epoch_start_i:,1]))\n",
    "    \n",
    "print \"Learning time: \", time.time() - t, \" seconds\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting network parameters from after epoch 70\n",
      "Test error rate is 21.050000%\n",
      "Train error rate is 15.742500%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f3b1430ead0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEDCAYAAAAvNJM9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f3b373aa790>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print \"Setting network parameters from after epoch %d\" %(best_params_epoch)\n",
    "load_parameters(best_params)\n",
    "\n",
    "print \"Test error rate is %f%%\" %(compute_error_rate(cifar10_test_stream)*100.0,)\n",
    "print \"Train error rate is %f%%\" %(compute_error_rate(cifar10_train_stream)*100.0,)\n",
    "\n",
    "subplot(2,1,1)\n",
    "train_nll_a = np.array(train_nll)\n",
    "semilogy(train_nll_a[:,0], train_nll_a[:,1], label='batch train nll')\n",
    "legend()\n",
    "\n",
    "subplot(2,1,2)\n",
    "train_erros_a = np.array(train_erros)\n",
    "plot(train_erros_a[:,0], train_erros_a[:,1], label='batch train error rate')\n",
    "validation_errors_a = np.array(validation_errors)\n",
    "plot(validation_errors_a[:,0], validation_errors_a[:,1], label='validation error rate', color='r')\n",
    "ylim(0,0.2)\n",
    "legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
